{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML4VA: Health Opportunity Index & Life Expectancy of Virginians"
      ],
      "metadata": {
        "id": "-ZJDF5WBsXq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CS 4774 Machine Learning - Department of Computer Science - University of Virginia\n",
        "\n"
      ],
      "metadata": {
        "id": "1gjuW1dFsvqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write-Up\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In order to predict the life expectancy of Virginian residents, we plan to use regression.In this task, the learning algorithm of *Linear Regression* is to be used in order to estimate a house price given other features and variables. \n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YgAqqoStswbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# General imports\n",
        "import sklearn # general ml package\n",
        "import numpy as np # fundamental package for scientific computing\n",
        "import os # to run file I/O operation \n",
        "\n",
        "# Set the seed (consistent throughout code)\n",
        "np.random.seed(55)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"end_to_end_project\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "  \"\"\"Save the selected figure into disc under an image extention and resolution\n",
        "  \"\"\"\n",
        "\n",
        "  path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "  print(\"Saving figure\", fig_id)\n",
        "  if tight_layout:\n",
        "    plt.tight_layout()\n",
        "  plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "metadata": {
        "id": "pGpL_K3Ftv_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "HOI = pd.read_csv('Health_Opportunity_Index.csv') # Reads CSV, converts into a PANDA object\n",
        "Life_Tract = pd.read_csv('Life_Expectancy_Census.csv')\n",
        "CountyCodes = pd.read_csv(\"Virginia_County_Codes.csv\")\n",
        "\n",
        "#data = pd.merge(HOI, Life_Tract, on='Census Tract', how='inner')\n",
        "CountyCodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OfYPa0l-tiST",
        "outputId": "03e5fa2d-92aa-4553-9603-608dcedd78fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Code               County\n",
              "0       1             Accomack\n",
              "1       3            Albemarle\n",
              "2       5            Alleghany\n",
              "3       7               Amelia\n",
              "4       9              Amherst\n",
              "..    ...                  ...\n",
              "123   800         Suffolk City\n",
              "124   810  Virginia Beach City\n",
              "125   820      Waynesboro City\n",
              "126   830    Williamsburg City\n",
              "127   840      Winchester City\n",
              "\n",
              "[128 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffdb25a1-a599-4040-ae46-1c068711c436\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>County</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Accomack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Albemarle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Alleghany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>Amelia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>Amherst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>800</td>\n",
              "      <td>Suffolk City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>810</td>\n",
              "      <td>Virginia Beach City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>820</td>\n",
              "      <td>Waynesboro City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>830</td>\n",
              "      <td>Williamsburg City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>840</td>\n",
              "      <td>Winchester City</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffdb25a1-a599-4040-ae46-1c068711c436')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ffdb25a1-a599-4040-ae46-1c068711c436 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ffdb25a1-a599-4040-ae46-1c068711c436');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "codes = {}\n",
        "for index, row in CountyCodes.iterrows():\n",
        "    #print(row['Code'], row['County'])\n",
        "    code = row['Code']\n",
        "    county = row['County']\n",
        "    codes[county] = code\n",
        "print(codes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_0XBCsh_X1k",
        "outputId": "f3f62627-f9f1-48e8-ccf3-a80f15368b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accomack': 1, 'Albemarle': 3, 'Alleghany': 5, 'Amelia': 7, 'Amherst': 9, 'Appomattox': 11, 'Arlington': 13, 'Augusta': 15, 'Bath': 17, 'Bedford': 19, 'Bland': 21, 'Botetourt': 23, 'Brunswick': 25, 'Buchanan': 27, 'Buckingham': 29, 'Campbell': 31, 'Caroline': 33, 'Carroll': 35, 'Charles City': 36, 'Charlotte': 37, 'Chesterfield': 41, 'Clarke': 43, 'Craig': 45, 'Culpeper': 47, 'Cumberland': 49, 'Dickenson': 51, 'Dinwiddie': 53, 'Essex': 57, 'Fairfax': 59, 'Fauquier': 61, 'Floyd': 63, 'Fluvanna': 65, 'Franklin': 67, 'Frederick': 69, 'Giles': 71, 'Gloucester': 73, 'Goochland': 75, 'Grayson': 77, 'Greene': 79, 'Greensville': 81, 'Halifax': 83, 'Hanover': 85, 'Henrico': 87, 'Henry': 89, 'Highland': 91, 'Isle of Wight': 93, 'James City': 95, 'King and Queen': 97, 'King George': 99, 'King William': 101, 'Lancaster': 103, 'Lee': 105, 'Loudoun': 107, 'Louisa': 109, 'Lunenburg': 111, 'Madison': 113, 'Mathews': 115, 'Mecklenburg': 117, 'Middlesex': 119, 'Montgomery': 121, 'Nelson': 125, 'New Kent': 127, 'Northampton': 131, 'Northumberland': 133, 'Nottoway': 135, 'Orange': 137, 'Page': 139, 'Patrick': 141, 'Pittsylvania': 143, 'Powhatan': 145, 'Prince Edward': 147, 'Prince George': 149, 'Prince William': 153, 'Pulaski': 155, 'Rappahannock': 157, 'Richmond': 159, 'Roanoke': 161, 'Rockbridge': 163, 'Rockingham': 165, 'Russell': 167, 'Scott': 169, 'Shenandoah': 171, 'Smyth': 173, 'Southampton': 175, 'Spotsylvania': 177, 'Stafford': 179, 'Surry': 181, 'Sussex': 183, 'Tazewell': 185, 'Warren': 187, 'Washington': 191, 'Westmoreland': 193, 'Wise': 195, 'Wythe': 197, 'York': 199, 'Alexandria City': 510, 'Bristol City': 520, 'Buena Vista City': 530, 'Charlottesville City': 540, 'Chesapeake City': 550, 'Colonial Heights City': 570, 'Danville City': 590, 'Falls Church City': 610, 'Franklin City': 620, 'Fredericksburg City': 630, 'Galax City': 640, 'Hampton City': 650, 'Harrisonburg City': 660, 'Hopewell City': 670, 'Lynchburg City': 680, 'Manassas City': 683, 'Martinsville City': 690, 'Newport News City': 700, 'Norfolk City': 710, 'Norton City': 720, 'Petersburg City': 730, 'Poquoson City': 735, 'Portsmouth City': 740, 'Radford City': 750, 'Richmond City': 760, 'Roanoke City': 770, 'Salem City': 775, 'Staunton City': 790, 'Suffolk City': 800, 'Virginia Beach City': 810, 'Waynesboro City': 820, 'Williamsburg City': 830, 'Winchester City': 840}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by Census Tract to clean data easier\n",
        "HOI = HOI.sort_values(by=['Census Tract'])\n",
        "Life_Tract = Life_Tract.sort_values(by=['Census Tract'])"
      ],
      "metadata": {
        "id": "maQxyxCJ_bi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean Life_Tract data to make it equal to county codes\n",
        "Life_Tract[\"County\"] = Life_Tract[\"County\"].str.replace(\", VA\",\"\")\n",
        "Life_Tract[\"County\"] = Life_Tract[\"County\"].str.replace(\" County\",\"\")\n",
        "Life_Tract[\"County\"] = Life_Tract[\"County\"].str.replace(\" city\",\" City\")"
      ],
      "metadata": {
        "id": "MPTITv5n_hal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Life_Tract.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "sfwQKZgy4RUJ",
        "outputId": "d76412f4-107e-437e-c0aa-9aae3cc9643f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         State                County  Census Tract  Life Expectancy  \\\n",
              "1732  Virginia          Roanoke City          1.00             74.8   \n",
              "1535  Virginia          Norfolk City          1.00              NaN   \n",
              "1397  Virginia   Fredericksburg City          1.00             80.1   \n",
              "1902  Virginia       Winchester City          1.00             74.5   \n",
              "1760  Virginia         Staunton City          1.00             78.4   \n",
              "909   Virginia              Nottoway          1.00             74.5   \n",
              "1369  Virginia         Danville City          1.00             78.7   \n",
              "1458  Virginia        Lynchburg City          1.00             81.8   \n",
              "1486  Virginia     Martinsville City          1.00              NaN   \n",
              "1439  Virginia     Harrisonburg City          1.01             75.3   \n",
              "1440  Virginia     Harrisonburg City          1.02             80.9   \n",
              "1370  Virginia         Danville City          2.00             71.4   \n",
              "1761  Virginia         Staunton City          2.00             72.1   \n",
              "910   Virginia              Nottoway          2.00             78.0   \n",
              "1487  Virginia     Martinsville City          2.00             70.0   \n",
              "1398  Virginia   Fredericksburg City          2.00             79.6   \n",
              "1536  Virginia          Norfolk City          2.01             74.2   \n",
              "1459  Virginia        Lynchburg City          2.01             83.6   \n",
              "1309  Virginia  Charlottesville City          2.01             78.7   \n",
              "1903  Virginia       Winchester City          2.01             82.2   \n",
              "\n",
              "     Life Expectancy Range  Life Expectancy Standard Error  \n",
              "1732             56.9-75.1                          1.6514  \n",
              "1535                   NaN                             NaN  \n",
              "1397             79.6-81.6                          1.5574  \n",
              "1902             56.9-75.1                          1.3690  \n",
              "1760             77.6-79.5                          1.7956  \n",
              "909              56.9-75.1                          1.1742  \n",
              "1369             77.6-79.5                          1.5963  \n",
              "1458             81.7-97.5                          1.0626  \n",
              "1486                   NaN                             NaN  \n",
              "1439             75.2-77.5                          1.8965  \n",
              "1440             79.6-81.6                          1.5062  \n",
              "1370             56.9-75.1                          1.6617  \n",
              "1761             56.9-75.1                          1.4382  \n",
              "910              77.6-79.5                          1.6538  \n",
              "1487             56.9-75.1                          1.8722  \n",
              "1398             79.6-81.6                          1.4354  \n",
              "1536             56.9-75.1                          1.8014  \n",
              "1459             81.7-97.5                          1.5872  \n",
              "1309             77.6-79.5                          3.2700  \n",
              "1903             81.7-97.5                          2.0388  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f66b35a0-0079-4c3b-b48a-932ecfc9b118\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>County</th>\n",
              "      <th>Census Tract</th>\n",
              "      <th>Life Expectancy</th>\n",
              "      <th>Life Expectancy Range</th>\n",
              "      <th>Life Expectancy Standard Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1732</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Roanoke City</td>\n",
              "      <td>1.00</td>\n",
              "      <td>74.8</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.6514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1535</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Norfolk City</td>\n",
              "      <td>1.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Fredericksburg City</td>\n",
              "      <td>1.00</td>\n",
              "      <td>80.1</td>\n",
              "      <td>79.6-81.6</td>\n",
              "      <td>1.5574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1902</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Winchester City</td>\n",
              "      <td>1.00</td>\n",
              "      <td>74.5</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.3690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1760</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Staunton City</td>\n",
              "      <td>1.00</td>\n",
              "      <td>78.4</td>\n",
              "      <td>77.6-79.5</td>\n",
              "      <td>1.7956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>909</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Nottoway</td>\n",
              "      <td>1.00</td>\n",
              "      <td>74.5</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.1742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1369</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Danville City</td>\n",
              "      <td>1.00</td>\n",
              "      <td>78.7</td>\n",
              "      <td>77.6-79.5</td>\n",
              "      <td>1.5963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Lynchburg City</td>\n",
              "      <td>1.00</td>\n",
              "      <td>81.8</td>\n",
              "      <td>81.7-97.5</td>\n",
              "      <td>1.0626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1486</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Martinsville City</td>\n",
              "      <td>1.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Harrisonburg City</td>\n",
              "      <td>1.01</td>\n",
              "      <td>75.3</td>\n",
              "      <td>75.2-77.5</td>\n",
              "      <td>1.8965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1440</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Harrisonburg City</td>\n",
              "      <td>1.02</td>\n",
              "      <td>80.9</td>\n",
              "      <td>79.6-81.6</td>\n",
              "      <td>1.5062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1370</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Danville City</td>\n",
              "      <td>2.00</td>\n",
              "      <td>71.4</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.6617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1761</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Staunton City</td>\n",
              "      <td>2.00</td>\n",
              "      <td>72.1</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.4382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>910</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Nottoway</td>\n",
              "      <td>2.00</td>\n",
              "      <td>78.0</td>\n",
              "      <td>77.6-79.5</td>\n",
              "      <td>1.6538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1487</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Martinsville City</td>\n",
              "      <td>2.00</td>\n",
              "      <td>70.0</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.8722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Fredericksburg City</td>\n",
              "      <td>2.00</td>\n",
              "      <td>79.6</td>\n",
              "      <td>79.6-81.6</td>\n",
              "      <td>1.4354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1536</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Norfolk City</td>\n",
              "      <td>2.01</td>\n",
              "      <td>74.2</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.8014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Lynchburg City</td>\n",
              "      <td>2.01</td>\n",
              "      <td>83.6</td>\n",
              "      <td>81.7-97.5</td>\n",
              "      <td>1.5872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1309</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Charlottesville City</td>\n",
              "      <td>2.01</td>\n",
              "      <td>78.7</td>\n",
              "      <td>77.6-79.5</td>\n",
              "      <td>3.2700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1903</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Winchester City</td>\n",
              "      <td>2.01</td>\n",
              "      <td>82.2</td>\n",
              "      <td>81.7-97.5</td>\n",
              "      <td>2.0388</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f66b35a0-0079-4c3b-b48a-932ecfc9b118')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f66b35a0-0079-4c3b-b48a-932ecfc9b118 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f66b35a0-0079-4c3b-b48a-932ecfc9b118');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TractCodes = []\n",
        "for entry in Life_Tract['Census Tract']:\n",
        "  entry = format(entry, '.2f')\n",
        "  entry = str(entry).zfill(7)\n",
        "  entry = entry.replace(\".\",\"\")\n",
        "  TractCodes.append(entry)\n",
        "  #if entry < 1000:\n",
        "  #print(entry)\n",
        "print(TractCodes)\n",
        "print(len(TractCodes))"
      ],
      "metadata": {
        "id": "F6yoadOMKcpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390c7b43-f2f1-4bb9-e8ab-7e55df6750f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['000100', '000100', '000100', '000100', '000100', '000100', '000100', '000100', '000100', '000101', '000102', '000200', '000200', '000200', '000200', '000200', '000201', '000201', '000201', '000201', '000202', '000202', '000202', '000202', '000203', '000203', '000204', '000205', '000206', '000207', '000300', '000300', '000300', '000300', '000300', '000300', '000300', '000301', '000301', '000301', '000302', '000302', '000302', '000302', '000400', '000400', '000400', '000400', '000400', '000400', '000400', '000401', '000401', '000402', '000402', '000500', '000500', '000500', '000500', '000500', '000500', '000500', '000501', '000502', '000600', '000600', '000600', '000600', '000600', '000601', '000602', '000700', '000700', '000700', '000700', '000800', '000800', '000800', '000801', '000802', '000900', '000900', '000900', '000900', '000901', '000902', '001000', '001000', '001000', '001000', '001100', '001100', '001100', '001100', '001200', '001200', '001200', '001300', '001301', '001302', '001400', '001400', '001400', '001500', '001600', '001600', '001700', '001700', '001800', '001800', '001900', '001900', '002000', '002100', '002100', '002200', '002200', '002300', '002300', '002400', '002400', '002500', '002500', '002600', '002600', '002700', '002700', '002800', '002800', '002900', '002900', '003000', '003000', '003100', '003100', '003100', '003200', '003200', '003300', '003300', '003400', '003400', '003500', '003501', '003600', '003700', '003800', '004001', '004002', '004100', '004200', '004300', '004400', '004500', '004600', '004700', '004800', '004900', '005000', '005100', '005500', '005601', '005602', '005701', '005702', '005800', '005901', '005902', '005903', '006000', '006100', '006200', '006400', '006501', '006502', '006601', '006602', '006603', '006604', '006605', '006606', '006607', '006800', '006901', '006902', '007001', '007002', '010100', '010100', '010100', '010100', '010100', '010100', '010100', '010100', '010100', '010100', '010101', '010102', '010103', '010103', '010104', '010105', '010106', '010107', '010108', '010200', '010200', '010200', '010200', '010200', '010200', '010200', '010200', '010200', '010200', '010200', '010200', '010201', '010201', '010202', '010202', '010204', '010205', '010206', '010207', '010210', '010211', '010212', '010213', '010214', '010300', '010300', '010300', '010300', '010300', '010300', '010300', '010300', '010300', '010300', '010300', '010301', '010303', '010304', '010304', '010305', '010306', '010307', '010309', '010310', '010311', '010312', '010313', '010314', '010400', '010400', '010400', '010400', '010400', '010400', '010401', '010401', '010401', '010401', '010402', '010402', '010402', '010402', '010403', '010404', '010405', '010406', '010500', '010500', '010500', '010500', '010500', '010500', '010501', '010501', '010501', '010502', '010502', '010502', '010502', '010502', '010503', '010503', '010504', '010504', '010600', '010600', '010600', '010600', '010600', '010601', '010601', '010601', '010601', '010602', '010602', '010602', '010602', '010700', '010700', '010700', '010700', '010700', '010700', '010700', '010701', '010702', '010703', '010800', '010800', '010800', '010800', '010800', '010800', '010801', '010802', '010900', '010900', '010900', '010900', '010900', '010900', '010901', '010902', '010903', '011000', '011000', '011000', '011000', '011000', '011000', '011001', '011002', '011100', '011100', '011100', '011100', '011100', '011100', '011200', '011200', '011200', '011200', '011201', '011202', '011300', '011300', '011300', '011301', '011302', '011303', '011400', '011400', '011400', '011400', '011500', '011500', '011600', '011600', '011700', '011800', '011800', '011900', '011900', '012000', '012000', '012100', '020001', '020002', '020003', '020100', '020100', '020100', '020100', '020100', '020100', '020100', '020101', '020101', '020101', '020102', '020102', '020102', '020104', '020105', '020106', '020107', '020108', '020109', '020110', '020111', '020112', '020113', '020114', '020200', '020200', '020200', '020200', '020200', '020200', '020200', '020200', '020200', '020201', '020201', '020202', '020202', '020203', '020204', '020205', '020300', '020300', '020300', '020300', '020300', '020300', '020300', '020300', '020300', '020300', '020304', '020305', '020306', '020307', '020308', '020309', '020310', '020311', '020400', '020400', '020400', '020400', '020400', '020400', '020400', '020401', '020402', '020403', '020403', '020404', '020405', '020406', '020407', '020408', '020500', '020500', '020500', '020500', '020500', '020500', '020500', '020600', '020600', '020600', '020600', '020600', '020600', '020601', '020602', '020700', '020700', '020700', '020700', '020700', '020700', '020700', '020800', '020800', '020800', '020800', '020800', '020804', '020805', '020806', '020807', '020808', '020809', '020900', '020900', '020900', '020900', '020900', '020903', '020904', '020905', '020906', '021000', '021000', '021000', '021004', '021005', '021006', '021009', '021010', '021011', '021012', '021013', '021100', '021100', '021100', '021101', '021102', '021200', '021200', '021200', '021300', '021301', '021302', '021400', '021401', '021402', '021403', '021404', '021500', '021501', '021502', '021601', '021602', '030100', '030100', '030100', '030100', '030100', '030100', '030100', '030100', '030100', '030100', '030101', '030101', '030102', '030103', '030104', '030200', '030200', '030200', '030200', '030200', '030200', '030200', '030200', '030201', '030201', '030201', '030202', '030202', '030203', '030204', '030205', '030300', '030300', '030300', '030300', '030300', '030300', '030300', '030300', '030301', '030301', '030302', '030302', '030400', '030400', '030400', '030400', '030400', '030401', '030401', '030402', '030402', '030500', '030500', '030500', '030500', '030500', '030500', '030500', '030500', '030501', '030503', '030504', '030600', '030600', '030600', '030600', '030600', '030600', '030601', '030602', '030603', '030604', '030605', '030701', '030701', '030702', '030702', '030800', '030801', '030802', '030900', '030900', '031000', '031100', '031101', '031102', '031200', '031201', '031202', '031300', '031400', '031500', '031601', '031602', '031701', '031702', '031800', '031901', '031902', '032001', '032002', '032005', '032006', '032007', '032113', '032114', '032117', '032123', '032124', '032126', '032127', '032128', '032129', '032130', '032131', '032132', '032211', '032212', '032223', '032224', '032225', '032226', '032300', '032400', '040000', '040100', '040100', '040100', '040100', '040100', '040100', '040100', '040200', '040200', '040200', '040200', '040200', '040200', '040200', '040200', '040201', '040202', '040300', '040300', '040300', '040300', '040300', '040301', '040302', '040400', '040400', '040400', '040400', '040401', '040402', '040402', '040403', '040404', '040500', '040500', '040500', '040501', '040502', '040600', '040600', '040600', '040700', '040700', '040800', '040800', '040801', '040802', '040900', '041000', '041002', '041003', '041004', '041100', '041200', '041200', '041300', '041400', '041400', '041600', '041600', '041801', '041802', '042000', '042201', '042202', '042400', '042600', '042801', '042802', '043002', '043003', '043004', '043200', '043400', '043600', '043800', '044001', '044003', '044004', '044200', '044401', '044402', '044600', '044805', '044806', '044807', '044808', '045000', '045200', '045405', '045406', '045407', '045408', '045412', '045414', '045415', '045417', '045420', '045421', '045422', '045423', '045424', '045425', '045426', '045427', '045428', '045601', '045603', '045604', '045801', '045803', '045805', '045806', '045807', '045808', '045809', '045810', '046002', '046005', '046006', '046009', '046010', '046011', '046012', '046013', '046014', '046015', '046016', '046204', '046206', '046207', '046211', '046212', '046213', '046214', '046216', '046217', '046219', '046220', '046221', '046222', '046223', '046224', '046225', '046400', '050100', '050100', '050100', '050100', '050100', '050200', '050200', '050200', '050203', '050204', '050205', '050206', '050300', '050300', '050301', '050302', '050303', '050304', '050305', '050306', '050400', '050400', '050401', '050401', '050402', '050402', '050500', '050500', '050500', '050600', '050600', '050700', '050801', '050802', '050803', '050900', '050900', '051000', '051000', '051100', '051101', '051102', '060100', '060101', '060102', '060200', '060200', '060201', '060202', '060300', '060400', '060500', '060600', '060700', '060800', '060900', '061000', '065100', '065200', '065300', '065400', '065500', '070100', '070100', '070100', '070101', '070102', '070200', '070300', '070300', '070400', '070400', '070500', '070600', '070601', '070602', '070700', '070700', '070800', '070801', '070802', '070900', '070900', '071000', '071001', '071002', '071100', '071101', '071102', '071200', '075101', '075102', '075201', '075202', '075203', '075204', '075301', '075302', '075401', '075402', '075403', '075404', '075405', '075501', '075502', '075601', '075602', '075701', '075702', '075703', '075801', '075802', '075803', '080100', '080100', '080101', '080102', '080200', '080201', '080202', '080202', '080203', '080205', '080206', '080300', '080301', '080301', '080302', '080303', '080304', '080400', '080401', '080402', '080500', '080601', '080602', '090100', '090100', '090200', '090200', '090300', '090400', '090500', '090600', '090700', '090800', '100100', '100100', '100106', '100107', '100200', '100201', '100202', '100203', '100205', '100206', '100208', '100209', '100210', '100300', '100300', '100301', '100302', '100400', '100400', '100403', '100404', '100405', '100406', '100407', '100409', '100410', '100500', '100500', '100505', '100506', '100507', '100508', '100509', '100510', '100600', '100600', '100700', '100701', '100702', '100703', '100800', '100804', '100805', '100806', '100807', '100812', '100814', '100815', '100816', '100817', '100818', '100819', '100820', '100821', '100822', '100823', '100900', '100902', '100907', '100910', '100912', '100915', '100919', '100920', '100921', '100922', '100923', '100924', '100926', '100927', '100928', '100929', '100930', '100931', '100932', '100933', '100934', '100935', '100936', '101000', '101003', '101004', '101007', '101008', '101009', '101010', '101011', '101012', '101013', '101100', '101200', '101300', '101401', '101402', '101403', '101404', '101500', '101601', '101602', '101603', '101701', '101702', '101703', '101801', '101802', '101803', '101900', '102001', '102002', '102003', '102100', '102200', '102301', '102302', '102400', '102500', '102600', '102701', '102702', '102801', '102802', '102901', '102902', '103000', '103100', '103200', '103300', '103401', '103402', '103501', '103502', '103503', '103601', '103602', '103700', '103800', '110102', '110103', '110104', '110200', '110300', '200100', '200102', '200103', '200104', '200104', '200105', '200105', '200106', '200106', '200107', '200107', '200108', '200109', '200112', '200116', '200119', '200120', '200121', '200122', '200123', '200124', '200125', '200126', '200127', '200128', '200129', '200130', '200200', '200201', '200201', '200202', '200202', '200300', '200301', '200301', '200302', '200302', '200303', '200303', '200305', '200400', '200403', '200404', '200404', '200405', '200406', '200406', '200407', '200407', '200409', '200410', '200411', '200412', '200413', '200414', '200500', '200500', '200501', '200502', '200503', '200600', '200600', '200700', '200701', '200702', '200703', '200801', '200801', '200802', '200802', '200804', '200805', '200900', '200903', '200904', '200905', '200906', '201000', '201001', '201002', '201003', '201100', '201101', '201102', '201201', '201202', '201202', '201203', '201204', '201300', '201400', '201401', '201403', '201404', '201500', '201501', '201502', '201600', '201601', '201602', '201701', '201801', '201802', '201900', '202001', '202002', '210100', '210200', '210201', '210202', '210300', '210300', '210400', '210400', '210500', '210500', '210600', '210600', '210700', '210900', '211100', '211400', '211500', '211600', '211700', '211800', '211900', '212000', '212100', '212300', '212400', '212500', '212600', '212701', '212702', '212801', '212802', '212900', '213001', '213002', '213101', '213103', '213104', '213200', '280101', '280103', '280104', '280105', '280106', '280200', '280300', '280400', '300100', '300200', '300300', '300400', '300500', '320100', '320200', '320300', '320400', '320500', '320601', '320602', '320701', '320702', '320801', '320803', '320804', '320805', '320900', '321001', '321002', '321100', '321201', '321202', '321300', '321401', '321402', '321403', '340100', '340200', '340300', '370100', '370200', '370300', '400100', '400200', '400300', '400400', '400500', '415100', '415200', '415300', '415401', '415402', '415500', '415600', '415700', '415800', '415900', '416000', '416100', '416200', '416300', '420100', '420201', '420202', '420203', '420300', '420400', '420501', '420502', '420503', '420600', '420700', '420800', '421001', '421002', '421101', '421102', '421103', '421200', '421300', '421400', '421500', '421600', '421701', '421702', '421800', '421900', '422000', '422101', '422102', '422201', '422202', '422301', '422302', '422401', '422402', '422403', '430101', '430102', '430201', '430202', '430203', '430400', '430500', '430600', '430700', '430801', '430802', '430901', '430902', '431001', '431002', '431300', '431400', '431500', '431600', '431801', '431802', '431900', '432000', '432100', '432201', '432202', '432300', '432401', '432402', '432500', '432600', '432701', '432702', '432800', '440100', '440201', '440202', '440300', '440501', '440502', '440600', '440701', '440702', '440800', '450100', '450200', '450300', '450400', '450500', '450601', '450602', '450701', '450702', '450800', '450900', '451000', '451100', '451200', '451300', '451400', '451501', '451502', '451601', '451602', '451800', '451900', '452000', '452101', '452102', '452200', '452301', '452302', '452400', '452501', '452502', '452600', '452700', '452801', '452802', '460100', '460200', '460300', '460400', '460501', '460502', '460600', '460701', '460702', '460800', '460900', '461000', '461100', '461201', '461202', '461500', '461601', '461602', '461700', '461801', '461802', '461901', '461902', '470100', '470300', '470400', '470500', '470600', '470700', '470800', '470900', '471000', '471100', '471201', '471202', '471301', '471303', '471304', '471401', '471402', '480100', '480201', '480202', '480203', '480300', '480401', '480402', '480501', '480502', '480503', '480504', '480505', '480801', '480802', '480901', '480902', '480903', '481000', '481101', '481102', '481103', '481104', '481105', '481106', '481201', '481202', '481400', '481500', '481600', '481701', '481702', '481900', '482001', '482002', '482100', '482201', '482202', '482203', '482301', '482302', '482303', '482400', '482501', '482502', '482503', '482504', '482601', '482602', '490101', '490103', '490501', '490502', '491000', '491101', '491102', '491103', '491201', '491202', '491301', '491302', '491303', '491401', '491402', '491403', '491404', '491405', '491501', '491502', '491601', '491602', '491701', '491702', '491703', '491704', '491705', '491801', '491802', '491803', '492000', '492100', '492201', '492202', '492203', '492300', '492400', '492500', '500100', '500101', '500102', '500200', '500200', '500300', '500300', '500400', '600100', '600200', '600300', '610101', '610102', '610201', '610202', '610300', '610400', '610503', '610504', '610505', '610506', '610507', '610601', '610602', '610603', '610604', '610701', '610702', '610703', '610800', '610900', '611002', '611004', '611005', '611006', '611009', '611010', '611011', '611012', '611013', '611014', '611015', '611016', '611017', '611018', '611019', '611020', '611021', '611022', '611023', '611024', '611025', '611101', '611102', '611202', '611204', '611205', '611206', '611207', '611208', '611209', '611300', '611400', '611501', '611502', '611601', '611602', '611700', '611801', '611802', '611803', '611804', '611805', '611806', '611900', '700100', '700200', '700300', '810100', '810300', '810400', '810500', '810600', '810700', '810900', '811000', '811100', '811200', '811300', '820100', '820300', '820400', '820500', '820600', '820700', '830100', '830200', '830300', '830400', '830500', '840100', '840200', '840300', '840400', '840500', '840600', '850100', '850200', '850301', '850302', '850400', '850501', '850502', '860100', '860200', '870100', '870201', '870202', '870300', '870400', '880101', '880102', '880200', '890100', '890200', '900100', '900201', '900202', '900203', '900300', '900403', '900404', '900407', '900408', '900409', '900410', '900501', '900502', '900600', '900701', '900702', '900801', '900802', '900901', '900904', '900905', '901001', '901005', '901008', '901009', '901010', '901011', '901012', '901100', '901203', '901208', '901209', '901211', '901212', '901219', '901221', '901222', '901223', '901224', '901225', '901226', '901227', '901228', '901229', '901230', '901231', '901232', '901233', '901234', '901235', '901236', '901237', '901303', '901304', '901305', '901306', '901403', '901407', '901408', '901409', '901410', '901411', '901412', '901413', '901414', '901415', '901416', '901417', '901503', '901504', '901505', '901506', '901507', '901508', '901509', '901510', '901511', '901601', '901602', '901701', '901702', '901900', '910100', '910201', '910202', '910301', '910302', '910401', '910402', '920100', '920100', '920101', '920102', '920200', '920200', '930100', '930100', '930100', '930100', '930100', '930100', '930100', '930100', '930100', '930100', '930100', '930100', '930101', '930101', '930101', '930102', '930102', '930102', '930200', '930200', '930200', '930200', '930200', '930200', '930200', '930200', '930200', '930201', '930201', '930201', '930201', '930201', '930202', '930202', '930202', '930202', '930202', '930203', '930203', '930203', '930204', '930205', '930206', '930207', '930300', '930300', '930300', '930300', '930300', '930300', '930300', '930300', '930300', '930301', '930302', '930302', '930303', '930304', '930400', '930400', '930400', '930400', '930400', '930401', '930402', '930403', '930500', '930500', '930500', '930501', '930502', '930600', '930600', '930600', '930700', '930700', '930703', '930704', '930705', '930706', '930707', '930800', '930800', '930800', '930900', '931000', '931100', '931200', '931300', '931400', '931500', '931600', '931700', '950100', '950100', '950100', '950100', '950101', '950102', '950200', '950200', '950200', '950200', '950201', '950202', '950300', '950300', '950300', '950300', '950400', '950400', '950400', '950500', '950500', '950500', '950600', '950600', '950700', '950800', '950900', '951000', '951100', '951200', '951300', '951400', '960100', '970100', '980100', '980100', '980100', '980100', '980100', '980100', '980100', '980100', '980100', '980100', '980100', '980100', '980100', '980200', '980200', '980200', '980200', '980200', '980300', '980300', '990000', '990100', '990100', '990100', '990100', '990100', '990100', '990100', '990100', '990100', '990100', '990200']\n",
            "1907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TractCounties = []\n",
        "for county in Life_Tract['County']:\n",
        "  try:\n",
        "    codeVal = codes[county]\n",
        "    # Make same length, 3 digits for county codes\n",
        "    codeVal = str(codeVal).zfill(3)\n",
        "\n",
        "    #print(\"County: \", county, \"Code: \", codeVal)\n",
        "    TractCounties.append(codeVal)\n",
        "  except KeyError:\n",
        "    # If it's a bad data point (e.g. a City not a county, we put 000 as the code, which doesn't exist)\n",
        "    TractCounties.append(\"000\")\n",
        "    #print(\"ERROR\")\n",
        "print(TractCounties)\n",
        "print(len(TractCounties))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtB9eItfKdeM",
        "outputId": "45e036bc-2092-46ac-f1b9-6d87a8d09be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['770', '710', '630', '840', '790', '135', '590', '680', '690', '660', '660', '590', '790', '135', '690', '630', '710', '680', '540', '840', '680', '540', '710', '840', '660', '680', '660', '660', '660', '660', '690', '680', '135', '770', '590', '790', '710', '630', '660', '840', '630', '660', '540', '840', '710', '680', '590', '770', '690', '630', '790', '660', '540', '540', '660', '630', '690', '790', '770', '680', '710', '590', '540', '540', '710', '540', '680', '590', '790', '770', '770', '540', '590', '710', '680', '710', '540', '590', '680', '680', '540', '770', '590', '680', '710', '710', '680', '770', '590', '540', '680', '770', '590', '710', '710', '770', '590', '710', '590', '590', '710', '680', '590', '710', '680', '710', '680', '710', '680', '770', '770', '680', '710', '770', '710', '770', '710', '770', '710', '710', '770', '710', '770', '770', '710', '710', '770', '710', '770', '710', '770', '710', '770', '710', '820', '770', '710', '820', '820', '710', '710', '820', '820', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '710', '043', '191', '027', '165', '089', '009', '003', '775', '143', '193', '750', '750', '650', '179', '650', '179', '179', '179', '179', '760', '750', '193', '009', '043', '191', '165', '027', '775', '143', '650', '089', '003', '179', '003', '179', '179', '179', '179', '179', '179', '179', '179', '179', '179', '143', '775', '191', '193', '760', '003', '043', '009', '089', '165', '027', '179', '179', '179', '650', '179', '650', '650', '650', '650', '650', '650', '650', '650', '165', '650', '143', '193', '027', '089', '009', '191', '760', '003', '003', '191', '009', '760', '179', '179', '179', '179', '760', '089', '165', '143', '027', '003', '775', '650', '191', '650', '191', '009', '179', '775', '009', '179', '009', '179', '165', '760', '009', '143', '027', '191', '650', '089', '003', '003', '650', '191', '089', '191', '089', '027', '165', '143', '003', '760', '650', '650', '650', '760', '650', '003', '089', '165', '191', '143', '143', '165', '650', '191', '760', '089', '143', '003', '003', '003', '003', '165', '760', '650', '191', '089', '143', '143', '760', '143', '003', '650', '089', '165', '143', '089', '165', '650', '003', '003', '143', '650', '089', '003', '003', '003', '650', '143', '003', '165', '650', '165', '165', '650', '165', '165', '650', '650', '165', '650', '165', '650', '550', '550', '550', '187', '760', '133', '550', '185', '121', '520', '065', '067', '031', '065', '067', '031', '177', '177', '177', '177', '177', '177', '177', '177', '177', '177', '177', '760', '031', '067', '187', '520', '065', '133', '550', '185', '121', '177', '177', '121', '177', '177', '177', '520', '121', '760', '133', '067', '185', '065', '187', '031', '550', '177', '177', '177', '177', '177', '177', '177', '177', '067', '550', '520', '121', '185', '187', '760', '031', '031', '177', '031', '177', '177', '177', '177', '177', '031', '187', '121', '760', '550', '185', '067', '550', '067', '760', '121', '031', '185', '187', '187', '760', '185', '550', '031', '187', '121', '067', '067', '185', '121', '760', '031', '550', '550', '550', '550', '550', '550', '121', '185', '067', '760', '031', '550', '550', '550', '550', '185', '121', '760', '550', '550', '550', '550', '550', '550', '550', '550', '121', '185', '760', '550', '550', '550', '121', '760', '121', '550', '550', '121', '550', '550', '550', '550', '121', '550', '550', '550', '550', '033', '173', '141', '169', '161', '139', '760', '167', '700', '103', '019', '079', '079', '019', '019', '173', '079', '103', '167', '169', '139', '141', '760', '161', '033', '019', '033', '019', '161', '161', '161', '161', '139', '169', '167', '700', '019', '033', '103', '141', '173', '173', '141', '139', '033', '169', '700', '173', '167', '019', '019', '167', '161', '760', '033', '167', '173', '139', '169', '700', '019', '019', '019', '700', '033', '173', '169', '167', '161', '019', '019', '019', '019', '019', '173', '161', '173', '161', '700', '161', '161', '161', '700', '161', '700', '161', '161', '700', '161', '161', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '700', '810', '099', '011', '023', '021', '159', '171', '051', '023', '011', '021', '760', '810', '159', '051', '099', '171', '171', '011', '760', '099', '051', '171', '023', '023', '051', '099', '171', '760', '023', '810', '023', '810', '810', '171', '099', '760', '023', '023', '810', '171', '760', '171', '760', '171', '760', '810', '810', '760', '760', '810', '810', '810', '760', '810', '760', '760', '760', '810', '810', '760', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '810', '197', '069', '045', '760', '019', '197', '069', '760', '199', '199', '199', '199', '760', '069', '197', '197', '199', '199', '199', '199', '760', '069', '197', '199', '197', '199', '760', '069', '199', '069', '760', '069', '069', '069', '069', '199', '069', '069', '199', '199', '069', '069', '000', '077', '077', '000', '760', '077', '077', '077', '760', '760', '760', '760', '760', '760', '760', '800', '800', '800', '800', '800', '005', '760', '015', '640', '640', '015', '015', '760', '760', '015', '015', '015', '760', '760', '760', '015', '015', '760', '760', '760', '015', '015', '760', '760', '760', '015', '015', '015', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '800', '005', '035', '095', '095', '035', '005', '095', '005', '095', '095', '095', '035', '095', '005', '005', '095', '095', '035', '095', '095', '035', '035', '035', '620', '001', '001', '620', '001', '001', '001', '001', '001', '001', '073', '013', '041', '041', '013', '073', '073', '073', '041', '041', '041', '041', '041', '013', '041', '073', '073', '013', '073', '041', '041', '041', '041', '041', '041', '041', '013', '073', '041', '041', '041', '041', '041', '041', '013', '041', '013', '041', '041', '041', '013', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '013', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '041', '013', '041', '041', '041', '041', '041', '041', '041', '041', '041', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '013', '137', '137', '137', '137', '137', '175', '510', '510', '087', '510', '510', '087', '510', '087', '510', '087', '087', '087', '087', '087', '087', '087', '087', '087', '087', '087', '087', '087', '087', '087', '087', '087', '175', '087', '510', '087', '510', '175', '087', '510', '510', '087', '510', '087', '087', '175', '510', '510', '087', '510', '510', '087', '510', '087', '087', '087', '087', '087', '087', '087', '510', '175', '087', '087', '087', '510', '087', '087', '510', '510', '510', '087', '510', '087', '510', '087', '087', '510', '087', '087', '087', '087', '510', '087', '087', '087', '510', '087', '087', '087', '087', '510', '510', '510', '510', '510', '087', '087', '087', '510', '087', '087', '510', '087', '087', '087', '510', '510', '510', '510', '510', '155', '740', '155', '155', '740', '155', '155', '740', '155', '740', '155', '740', '155', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '740', '093', '093', '093', '093', '093', '093', '093', '093', '000', '000', '000', '000', '000', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '085', '735', '735', '735', '830', '830', '830', '075', '075', '075', '075', '075', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '059', '610', '145', '145', '145', '610', '610', '145', '145', '036', '036', '036', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '107', '127', '127', '127', '730', '730', '730', '730', '730', '730', '730', '730', '730', '730', '730', '670', '670', '670', '670', '670', '670', '570', '570', '570', '570', '570', '053', '053', '053', '053', '053', '053', '149', '149', '149', '149', '149', '149', '149', '181', '181', '183', '183', '183', '183', '183', '081', '081', '081', '000', '000', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '153', '683', '683', '683', '683', '683', '683', '683', '017', '000', '063', '063', '000', '063', '113', '111', '071', '083', '037', '049', '025', '163', '147', '007', '131', '061', '029', '117', '047', '029', '047', '117', '071', '113', '163', '111', '131', '037', '049', '117', '007', '025', '047', '083', '029', '147', '025', '083', '147', '029', '047', '025', '061', '147', '061', '061', '061', '061', '025', '117', '163', '147', '047', '071', '111', '037', '131', '083', '083', '061', '061', '061', '117', '163', '071', '047', '083', '061', '061', '061', '117', '000', '083', '047', '047', '083', '530', '117', '117', '195', '061', '061', '061', '061', '061', '083', '195', '117', '195', '195', '195', '195', '195', '195', '195', '195', '195', '105', '109', '157', '125', '101', '101', '157', '101', '105', '125', '109', '109', '101', '105', '125', '109', '097', '105', '109', '105', '109', '097', '105', '057', '057', '057', '119', '119', '119', '119', '115', '115', '720', '091', '153', '107', '155', '087', '710', '001', '670', '059', '013', '135', '053', '590', '740', '710', '059', '155', '001', '013', '710', '059', '710', '650', '001', '103', '735', '199', '131', '133', '119', '810', '115', '001']\n",
            "1907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TractCountiesClean = []\n",
        "TractCodesClean = []\n",
        "TractIndexes = []\n",
        "badIndexes = []\n",
        "for i, num in enumerate(TractCounties):\n",
        "  if num != \"000\":\n",
        "    TractCountiesClean.append(num)\n",
        "    TractCodesClean.append(TractCodes[i])\n",
        "    TractIndexes.append(i)\n",
        "  else:\n",
        "    badIndexes.append(i)\n",
        "print(\"Len of Counties: \", len(TractCountiesClean))\n",
        "print(\"Len of Codes: \", len(TractCodesClean))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cANajUcsKedW",
        "outputId": "a453cf5c-9fd8-4246-e183-30031048702c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len of Counties:  1895\n",
            "Len of Codes:  1895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "geoids = []\n",
        "IndexMap = {}\n",
        "for i, code in enumerate(TractCodesClean):\n",
        "  countyNum = TractCountiesClean[i]\n",
        "  combID = countyNum + code\n",
        "  geoids.append(combID)\n",
        "  IndexMap[combID] = TractIndexes[i]\n",
        "print(\"9-digit geo IDS: \", geoids)\n",
        "print(\"Map of indexes: \", IndexMap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq1z5ylsKgQv",
        "outputId": "fd043c44-46a3-4617-e98c-7e8df4694853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9-digit geo IDS:  ['770000100', '710000100', '630000100', '840000100', '790000100', '135000100', '590000100', '680000100', '690000100', '660000101', '660000102', '590000200', '790000200', '135000200', '690000200', '630000200', '710000201', '680000201', '540000201', '840000201', '680000202', '540000202', '710000202', '840000202', '660000203', '680000203', '660000204', '660000205', '660000206', '660000207', '690000300', '680000300', '135000300', '770000300', '590000300', '790000300', '710000300', '630000301', '660000301', '840000301', '630000302', '660000302', '540000302', '840000302', '710000400', '680000400', '590000400', '770000400', '690000400', '630000400', '790000400', '660000401', '540000401', '540000402', '660000402', '630000500', '690000500', '790000500', '770000500', '680000500', '710000500', '590000500', '540000501', '540000502', '710000600', '540000600', '680000600', '590000600', '790000600', '770000601', '770000602', '540000700', '590000700', '710000700', '680000700', '710000800', '540000800', '590000800', '680000801', '680000802', '540000900', '770000900', '590000900', '680000900', '710000901', '710000902', '680001000', '770001000', '590001000', '540001000', '680001100', '770001100', '590001100', '710001100', '710001200', '770001200', '590001200', '710001300', '590001301', '590001302', '710001400', '680001400', '590001400', '710001500', '680001600', '710001600', '680001700', '710001700', '680001800', '770001800', '770001900', '680001900', '710002000', '770002100', '710002100', '770002200', '710002200', '770002300', '710002300', '710002400', '770002400', '710002500', '770002500', '770002600', '710002600', '710002700', '770002700', '710002800', '770002800', '710002900', '770002900', '710003000', '770003000', '710003100', '820003100', '770003100', '710003200', '820003200', '820003300', '710003300', '710003400', '820003400', '820003500', '710003501', '710003600', '710003700', '710003800', '710004001', '710004002', '710004100', '710004200', '710004300', '710004400', '710004500', '710004600', '710004700', '710004800', '710004900', '710005000', '710005100', '710005500', '710005601', '710005602', '710005701', '710005702', '710005800', '710005901', '710005902', '710005903', '710006000', '710006100', '710006200', '710006400', '710006501', '710006502', '710006601', '710006602', '710006603', '710006604', '710006605', '710006606', '710006607', '710006800', '710006901', '710006902', '710007001', '710007002', '043010100', '191010100', '027010100', '165010100', '089010100', '009010100', '003010100', '775010100', '143010100', '193010100', '750010101', '750010102', '650010103', '179010103', '650010104', '179010105', '179010106', '179010107', '179010108', '760010200', '750010200', '193010200', '009010200', '043010200', '191010200', '165010200', '027010200', '775010200', '143010200', '650010200', '089010200', '003010201', '179010201', '003010202', '179010202', '179010204', '179010205', '179010206', '179010207', '179010210', '179010211', '179010212', '179010213', '179010214', '143010300', '775010300', '191010300', '193010300', '760010300', '003010300', '043010300', '009010300', '089010300', '165010300', '027010300', '179010301', '179010303', '179010304', '650010304', '179010305', '650010306', '650010307', '650010309', '650010310', '650010311', '650010312', '650010313', '650010314', '165010400', '650010400', '143010400', '193010400', '027010400', '089010400', '009010401', '191010401', '760010401', '003010401', '003010402', '191010402', '009010402', '760010402', '179010403', '179010404', '179010405', '179010406', '760010500', '089010500', '165010500', '143010500', '027010500', '003010500', '775010501', '650010501', '191010501', '650010502', '191010502', '009010502', '179010502', '775010502', '009010503', '179010503', '009010504', '179010504', '165010600', '760010600', '009010600', '143010600', '027010600', '191010601', '650010601', '089010601', '003010601', '003010602', '650010602', '191010602', '089010602', '191010700', '089010700', '027010700', '165010700', '143010700', '003010700', '760010700', '650010701', '650010702', '650010703', '760010800', '650010800', '003010800', '089010800', '165010800', '191010800', '143010801', '143010802', '165010900', '650010900', '191010900', '760010900', '089010900', '143010900', '003010901', '003010902', '003010903', '003011000', '165011000', '760011000', '650011000', '191011000', '089011000', '143011001', '143011002', '760011100', '143011100', '003011100', '650011100', '089011100', '165011100', '143011200', '089011200', '165011200', '650011200', '003011201', '003011202', '143011300', '650011300', '089011300', '003011301', '003011302', '003011303', '650011400', '143011400', '003011400', '165011400', '650011500', '165011500', '165011600', '650011600', '165011700', '165011800', '650011800', '650011900', '165011900', '650012000', '165012000', '650012100', '550020001', '550020002', '550020003', '187020100', '760020100', '133020100', '550020100', '185020100', '121020100', '520020100', '065020101', '067020101', '031020101', '065020102', '067020102', '031020102', '177020104', '177020105', '177020106', '177020107', '177020108', '177020109', '177020110', '177020111', '177020112', '177020113', '177020114', '760020200', '031020200', '067020200', '187020200', '520020200', '065020200', '133020200', '550020200', '185020200', '121020201', '177020201', '177020202', '121020202', '177020203', '177020204', '177020205', '520020300', '121020300', '760020300', '133020300', '067020300', '185020300', '065020300', '187020300', '031020300', '550020300', '177020304', '177020305', '177020306', '177020307', '177020308', '177020309', '177020310', '177020311', '067020400', '550020400', '520020400', '121020400', '185020400', '187020400', '760020400', '031020401', '031020402', '177020403', '031020403', '177020404', '177020405', '177020406', '177020407', '177020408', '031020500', '187020500', '121020500', '760020500', '550020500', '185020500', '067020500', '550020600', '067020600', '760020600', '121020600', '031020600', '185020600', '187020601', '187020602', '760020700', '185020700', '550020700', '031020700', '187020700', '121020700', '067020700', '067020800', '185020800', '121020800', '760020800', '031020800', '550020804', '550020805', '550020806', '550020807', '550020808', '550020809', '121020900', '185020900', '067020900', '760020900', '031020900', '550020903', '550020904', '550020905', '550020906', '185021000', '121021000', '760021000', '550021004', '550021005', '550021006', '550021009', '550021010', '550021011', '550021012', '550021013', '121021100', '185021100', '760021100', '550021101', '550021102', '550021200', '121021200', '760021200', '121021300', '550021301', '550021302', '121021400', '550021401', '550021402', '550021403', '550021404', '121021500', '550021501', '550021502', '550021601', '550021602', '033030100', '173030100', '141030100', '169030100', '161030100', '139030100', '760030100', '167030100', '700030100', '103030100', '019030101', '079030101', '079030102', '019030103', '019030104', '173030200', '079030200', '103030200', '167030200', '169030200', '139030200', '141030200', '760030200', '161030201', '033030201', '019030201', '033030202', '019030202', '161030203', '161030204', '161030205', '161030300', '139030300', '169030300', '167030300', '700030300', '019030300', '033030300', '103030300', '141030301', '173030301', '173030302', '141030302', '139030400', '033030400', '169030400', '700030400', '173030400', '167030401', '019030401', '019030402', '167030402', '161030500', '760030500', '033030500', '167030500', '173030500', '139030500', '169030500', '700030500', '019030501', '019030503', '019030504', '700030600', '033030600', '173030600', '169030600', '167030600', '161030600', '019030601', '019030602', '019030603', '019030604', '019030605', '173030701', '161030701', '173030702', '161030702', '700030800', '161030801', '161030802', '161030900', '700030900', '161031000', '700031100', '161031101', '161031102', '700031200', '161031201', '161031202', '700031300', '700031400', '700031500', '700031601', '700031602', '700031701', '700031702', '700031800', '700031901', '700031902', '700032001', '700032002', '700032005', '700032006', '700032007', '700032113', '700032114', '700032117', '700032123', '700032124', '700032126', '700032127', '700032128', '700032129', '700032130', '700032131', '700032132', '700032211', '700032212', '700032223', '700032224', '700032225', '700032226', '700032300', '700032400', '810040000', '099040100', '011040100', '023040100', '021040100', '159040100', '171040100', '051040100', '023040200', '011040200', '021040200', '760040200', '810040200', '159040200', '051040200', '099040200', '171040201', '171040202', '011040300', '760040300', '099040300', '051040300', '171040300', '023040301', '023040302', '051040400', '099040400', '171040400', '760040400', '023040401', '810040402', '023040402', '810040403', '810040404', '171040500', '099040500', '760040500', '023040501', '023040502', '810040600', '171040600', '760040600', '171040700', '760040700', '171040800', '760040800', '810040801', '810040802', '760040900', '760041000', '810041002', '810041003', '810041004', '760041100', '810041200', '760041200', '760041300', '760041400', '810041400', '810041600', '760041600', '810041801', '810041802', '810042000', '810042201', '810042202', '810042400', '810042600', '810042801', '810042802', '810043002', '810043003', '810043004', '810043200', '810043400', '810043600', '810043800', '810044001', '810044003', '810044004', '810044200', '810044401', '810044402', '810044600', '810044805', '810044806', '810044807', '810044808', '810045000', '810045200', '810045405', '810045406', '810045407', '810045408', '810045412', '810045414', '810045415', '810045417', '810045420', '810045421', '810045422', '810045423', '810045424', '810045425', '810045426', '810045427', '810045428', '810045601', '810045603', '810045604', '810045801', '810045803', '810045805', '810045806', '810045807', '810045808', '810045809', '810045810', '810046002', '810046005', '810046006', '810046009', '810046010', '810046011', '810046012', '810046013', '810046014', '810046015', '810046016', '810046204', '810046206', '810046207', '810046211', '810046212', '810046213', '810046214', '810046216', '810046217', '810046219', '810046220', '810046221', '810046222', '810046223', '810046224', '810046225', '810046400', '197050100', '069050100', '045050100', '760050100', '019050100', '197050200', '069050200', '760050200', '199050203', '199050204', '199050205', '199050206', '760050300', '069050300', '197050301', '197050302', '199050303', '199050304', '199050305', '199050306', '760050400', '069050400', '197050401', '199050401', '197050402', '199050402', '760050500', '069050500', '199050500', '069050600', '760050600', '069050700', '069050801', '069050802', '069050803', '199050900', '069050900', '069051000', '199051000', '199051100', '069051101', '069051102', '077060101', '077060102', '760060200', '077060201', '077060202', '077060300', '760060400', '760060500', '760060600', '760060700', '760060800', '760060900', '760061000', '800065100', '800065200', '800065300', '800065400', '800065500', '005070100', '760070100', '015070100', '640070101', '640070102', '015070200', '015070300', '760070300', '760070400', '015070400', '015070500', '015070600', '760070601', '760070602', '760070700', '015070700', '015070800', '760070801', '760070802', '760070900', '015070900', '015071000', '760071001', '760071002', '760071100', '015071101', '015071102', '015071200', '800075101', '800075102', '800075201', '800075202', '800075203', '800075204', '800075301', '800075302', '800075401', '800075402', '800075403', '800075404', '800075405', '800075501', '800075502', '800075601', '800075602', '800075701', '800075702', '800075703', '800075801', '800075802', '800075803', '005080100', '035080100', '095080101', '095080102', '035080200', '005080201', '095080202', '005080202', '095080203', '095080205', '095080206', '035080300', '095080301', '005080301', '005080302', '095080303', '095080304', '035080400', '095080401', '095080402', '035080500', '035080601', '035080602', '620090100', '001090100', '001090200', '620090200', '001090300', '001090400', '001090500', '001090600', '001090700', '001090800', '073100100', '013100100', '041100106', '041100107', '013100200', '073100201', '073100202', '073100203', '041100205', '041100206', '041100208', '041100209', '041100210', '013100300', '041100300', '073100301', '073100302', '013100400', '073100400', '041100403', '041100404', '041100405', '041100406', '041100407', '041100409', '041100410', '013100500', '073100500', '041100505', '041100506', '041100507', '041100508', '041100509', '041100510', '013100600', '041100600', '013100700', '041100701', '041100702', '041100703', '013100800', '041100804', '041100805', '041100806', '041100807', '041100812', '041100814', '041100815', '041100816', '041100817', '041100818', '041100819', '041100820', '041100821', '041100822', '041100823', '013100900', '041100902', '041100907', '041100910', '041100912', '041100915', '041100919', '041100920', '041100921', '041100922', '041100923', '041100924', '041100926', '041100927', '041100928', '041100929', '041100930', '041100931', '041100932', '041100933', '041100934', '041100935', '041100936', '013101000', '041101003', '041101004', '041101007', '041101008', '041101009', '041101010', '041101011', '041101012', '041101013', '013101100', '013101200', '013101300', '013101401', '013101402', '013101403', '013101404', '013101500', '013101601', '013101602', '013101603', '013101701', '013101702', '013101703', '013101801', '013101802', '013101803', '013101900', '013102001', '013102002', '013102003', '013102100', '013102200', '013102301', '013102302', '013102400', '013102500', '013102600', '013102701', '013102702', '013102801', '013102802', '013102901', '013102902', '013103000', '013103100', '013103200', '013103300', '013103401', '013103402', '013103501', '013103502', '013103503', '013103601', '013103602', '013103700', '013103800', '137110102', '137110103', '137110104', '137110200', '137110300', '175200100', '510200102', '510200103', '087200104', '510200104', '510200105', '087200105', '510200106', '087200106', '510200107', '087200107', '087200108', '087200109', '087200112', '087200116', '087200119', '087200120', '087200121', '087200122', '087200123', '087200124', '087200125', '087200126', '087200127', '087200128', '087200129', '087200130', '175200200', '087200201', '510200201', '087200202', '510200202', '175200300', '087200301', '510200301', '510200302', '087200302', '510200303', '087200303', '087200305', '175200400', '510200403', '510200404', '087200404', '510200405', '510200406', '087200406', '510200407', '087200407', '087200409', '087200410', '087200411', '087200412', '087200413', '087200414', '510200500', '175200500', '087200501', '087200502', '087200503', '510200600', '087200600', '087200700', '510200701', '510200702', '510200703', '087200801', '510200801', '087200802', '510200802', '087200804', '087200805', '510200900', '087200903', '087200904', '087200905', '087200906', '510201000', '087201001', '087201002', '087201003', '510201100', '087201101', '087201102', '087201201', '087201202', '510201202', '510201203', '510201204', '510201300', '510201400', '087201401', '087201403', '087201404', '510201500', '087201501', '087201502', '510201600', '087201601', '087201602', '087201701', '510201801', '510201802', '510201900', '510202001', '510202002', '155210100', '740210200', '155210201', '155210202', '740210300', '155210300', '155210400', '740210400', '155210500', '740210500', '155210600', '740210600', '155210700', '740210900', '740211100', '740211400', '740211500', '740211600', '740211700', '740211800', '740211900', '740212000', '740212100', '740212300', '740212400', '740212500', '740212600', '740212701', '740212702', '740212801', '740212802', '740212900', '740213001', '740213002', '740213101', '740213103', '740213104', '740213200', '093280101', '093280103', '093280104', '093280105', '093280106', '093280200', '093280300', '093280400', '085320100', '085320200', '085320300', '085320400', '085320500', '085320601', '085320602', '085320701', '085320702', '085320801', '085320803', '085320804', '085320805', '085320900', '085321001', '085321002', '085321100', '085321201', '085321202', '085321300', '085321401', '085321402', '085321403', '735340100', '735340200', '735340300', '830370100', '830370200', '830370300', '075400100', '075400200', '075400300', '075400400', '075400500', '059415100', '059415200', '059415300', '059415401', '059415402', '059415500', '059415600', '059415700', '059415800', '059415900', '059416000', '059416100', '059416200', '059416300', '059420100', '059420201', '059420202', '059420203', '059420300', '059420400', '059420501', '059420502', '059420503', '059420600', '059420700', '059420800', '059421001', '059421002', '059421101', '059421102', '059421103', '059421200', '059421300', '059421400', '059421500', '059421600', '059421701', '059421702', '059421800', '059421900', '059422000', '059422101', '059422102', '059422201', '059422202', '059422301', '059422302', '059422401', '059422402', '059422403', '059430101', '059430102', '059430201', '059430202', '059430203', '059430400', '059430500', '059430600', '059430700', '059430801', '059430802', '059430901', '059430902', '059431001', '059431002', '059431300', '059431400', '059431500', '059431600', '059431801', '059431802', '059431900', '059432000', '059432100', '059432201', '059432202', '059432300', '059432401', '059432402', '059432500', '059432600', '059432701', '059432702', '059432800', '059440100', '059440201', '059440202', '059440300', '059440501', '059440502', '059440600', '059440701', '059440702', '059440800', '059450100', '059450200', '059450300', '059450400', '059450500', '059450601', '059450602', '059450701', '059450702', '059450800', '059450900', '059451000', '059451100', '059451200', '059451300', '059451400', '059451501', '059451502', '059451601', '059451602', '059451800', '059451900', '059452000', '059452101', '059452102', '059452200', '059452301', '059452302', '059452400', '059452501', '059452502', '059452600', '059452700', '059452801', '059452802', '059460100', '059460200', '059460300', '059460400', '059460501', '059460502', '059460600', '059460701', '059460702', '059460800', '059460900', '059461000', '059461100', '059461201', '059461202', '059461500', '059461601', '059461602', '059461700', '059461801', '059461802', '059461901', '059461902', '059470100', '059470300', '059470400', '059470500', '059470600', '059470700', '059470800', '059470900', '059471000', '059471100', '059471201', '059471202', '059471301', '059471303', '059471304', '059471401', '059471402', '059480100', '059480201', '059480202', '059480203', '059480300', '059480401', '059480402', '059480501', '059480502', '059480503', '059480504', '059480505', '059480801', '059480802', '059480901', '059480902', '059480903', '059481000', '059481101', '059481102', '059481103', '059481104', '059481105', '059481106', '059481201', '059481202', '059481400', '059481500', '059481600', '059481701', '059481702', '059481900', '059482001', '059482002', '059482100', '059482201', '059482202', '059482203', '059482301', '059482302', '059482303', '059482400', '059482501', '059482502', '059482503', '059482504', '059482601', '059482602', '059490101', '059490103', '059490501', '059490502', '059491000', '059491101', '059491102', '059491103', '059491201', '059491202', '059491301', '059491302', '059491303', '059491401', '059491402', '059491403', '059491404', '059491405', '059491501', '059491502', '059491601', '059491602', '059491701', '059491702', '059491703', '059491704', '059491705', '059491801', '059491802', '059491803', '059492000', '059492100', '059492201', '059492202', '059492203', '059492300', '059492400', '059492500', '610500100', '145500101', '145500102', '145500200', '610500200', '610500300', '145500300', '145500400', '036600100', '036600200', '036600300', '107610101', '107610102', '107610201', '107610202', '107610300', '107610400', '107610503', '107610504', '107610505', '107610506', '107610507', '107610601', '107610602', '107610603', '107610604', '107610701', '107610702', '107610703', '107610800', '107610900', '107611002', '107611004', '107611005', '107611006', '107611009', '107611010', '107611011', '107611012', '107611013', '107611014', '107611015', '107611016', '107611017', '107611018', '107611019', '107611020', '107611021', '107611022', '107611023', '107611024', '107611025', '107611101', '107611102', '107611202', '107611204', '107611205', '107611206', '107611207', '107611208', '107611209', '107611300', '107611400', '107611501', '107611502', '107611601', '107611602', '107611700', '107611801', '107611802', '107611803', '107611804', '107611805', '107611806', '107611900', '127700100', '127700200', '127700300', '730810100', '730810300', '730810400', '730810500', '730810600', '730810700', '730810900', '730811000', '730811100', '730811200', '730811300', '670820100', '670820300', '670820400', '670820500', '670820600', '670820700', '570830100', '570830200', '570830300', '570830400', '570830500', '053840100', '053840200', '053840300', '053840400', '053840500', '053840600', '149850100', '149850200', '149850301', '149850302', '149850400', '149850501', '149850502', '181860100', '181860200', '183870100', '183870201', '183870202', '183870300', '183870400', '081880101', '081880102', '081880200', '153900100', '153900201', '153900202', '153900203', '153900300', '153900403', '153900404', '153900407', '153900408', '153900409', '153900410', '153900501', '153900502', '153900600', '153900701', '153900702', '153900801', '153900802', '153900901', '153900904', '153900905', '153901001', '153901005', '153901008', '153901009', '153901010', '153901011', '153901012', '153901100', '153901203', '153901208', '153901209', '153901211', '153901212', '153901219', '153901221', '153901222', '153901223', '153901224', '153901225', '153901226', '153901227', '153901228', '153901229', '153901230', '153901231', '153901232', '153901233', '153901234', '153901235', '153901236', '153901237', '153901303', '153901304', '153901305', '153901306', '153901403', '153901407', '153901408', '153901409', '153901410', '153901411', '153901412', '153901413', '153901414', '153901415', '153901416', '153901417', '153901503', '153901504', '153901505', '153901506', '153901507', '153901508', '153901509', '153901510', '153901511', '153901601', '153901602', '153901701', '153901702', '153901900', '683910100', '683910201', '683910202', '683910301', '683910302', '683910401', '683910402', '017920100', '063920101', '063920102', '063920200', '113930100', '111930100', '071930100', '083930100', '037930100', '049930100', '025930100', '163930100', '147930100', '007930100', '131930100', '061930100', '029930101', '117930101', '047930101', '029930102', '047930102', '117930102', '071930200', '113930200', '163930200', '111930200', '131930200', '037930200', '049930200', '117930200', '007930200', '025930201', '047930201', '083930201', '029930201', '147930201', '025930202', '083930202', '147930202', '029930202', '047930202', '025930203', '061930203', '147930203', '061930204', '061930205', '061930206', '061930207', '025930300', '117930300', '163930300', '147930300', '047930300', '071930300', '111930300', '037930300', '131930300', '083930301', '083930302', '061930302', '061930303', '061930304', '117930400', '163930400', '071930400', '047930400', '083930400', '061930401', '061930402', '061930403', '117930500', '083930500', '047930501', '047930502', '083930600', '530930600', '117930600', '117930700', '195930700', '061930703', '061930704', '061930705', '061930706', '061930707', '083930800', '195930800', '117930800', '195930900', '195931000', '195931100', '195931200', '195931300', '195931400', '195931500', '195931600', '195931700', '105950100', '109950100', '157950100', '125950100', '101950101', '101950102', '157950200', '101950200', '105950200', '125950200', '109950201', '109950202', '101950300', '105950300', '125950300', '109950300', '097950400', '105950400', '109950400', '105950500', '109950500', '097950500', '105950600', '057950600', '057950700', '057950800', '119950900', '119951000', '119951100', '119951200', '115951300', '115951400', '720960100', '091970100', '153980100', '107980100', '155980100', '087980100', '710980100', '001980100', '670980100', '059980100', '013980100', '135980100', '053980100', '590980100', '740980100', '710980200', '059980200', '155980200', '001980200', '013980200', '710980300', '059980300', '710990000', '650990100', '001990100', '103990100', '735990100', '199990100', '131990100', '133990100', '119990100', '810990100', '115990100', '001990200']\n",
            "Map of indexes:  {'770000100': 0, '710000100': 1, '630000100': 2, '840000100': 3, '790000100': 4, '135000100': 5, '590000100': 6, '680000100': 7, '690000100': 8, '660000101': 9, '660000102': 10, '590000200': 11, '790000200': 12, '135000200': 13, '690000200': 14, '630000200': 15, '710000201': 16, '680000201': 17, '540000201': 18, '840000201': 19, '680000202': 20, '540000202': 21, '710000202': 22, '840000202': 23, '660000203': 24, '680000203': 25, '660000204': 26, '660000205': 27, '660000206': 28, '660000207': 29, '690000300': 30, '680000300': 31, '135000300': 32, '770000300': 33, '590000300': 34, '790000300': 35, '710000300': 36, '630000301': 37, '660000301': 38, '840000301': 39, '630000302': 40, '660000302': 41, '540000302': 42, '840000302': 43, '710000400': 44, '680000400': 45, '590000400': 46, '770000400': 47, '690000400': 48, '630000400': 49, '790000400': 50, '660000401': 51, '540000401': 52, '540000402': 53, '660000402': 54, '630000500': 55, '690000500': 56, '790000500': 57, '770000500': 58, '680000500': 59, '710000500': 60, '590000500': 61, '540000501': 62, '540000502': 63, '710000600': 64, '540000600': 65, '680000600': 66, '590000600': 67, '790000600': 68, '770000601': 69, '770000602': 70, '540000700': 71, '590000700': 72, '710000700': 73, '680000700': 74, '710000800': 75, '540000800': 76, '590000800': 77, '680000801': 78, '680000802': 79, '540000900': 80, '770000900': 81, '590000900': 82, '680000900': 83, '710000901': 84, '710000902': 85, '680001000': 86, '770001000': 87, '590001000': 88, '540001000': 89, '680001100': 90, '770001100': 91, '590001100': 92, '710001100': 93, '710001200': 94, '770001200': 95, '590001200': 96, '710001300': 97, '590001301': 98, '590001302': 99, '710001400': 100, '680001400': 101, '590001400': 102, '710001500': 103, '680001600': 104, '710001600': 105, '680001700': 106, '710001700': 107, '680001800': 108, '770001800': 109, '770001900': 110, '680001900': 111, '710002000': 112, '770002100': 113, '710002100': 114, '770002200': 115, '710002200': 116, '770002300': 117, '710002300': 118, '710002400': 119, '770002400': 120, '710002500': 121, '770002500': 122, '770002600': 123, '710002600': 124, '710002700': 125, '770002700': 126, '710002800': 127, '770002800': 128, '710002900': 129, '770002900': 130, '710003000': 131, '770003000': 132, '710003100': 133, '820003100': 134, '770003100': 135, '710003200': 136, '820003200': 137, '820003300': 138, '710003300': 139, '710003400': 140, '820003400': 141, '820003500': 142, '710003501': 143, '710003600': 144, '710003700': 145, '710003800': 146, '710004001': 147, '710004002': 148, '710004100': 149, '710004200': 150, '710004300': 151, '710004400': 152, '710004500': 153, '710004600': 154, '710004700': 155, '710004800': 156, '710004900': 157, '710005000': 158, '710005100': 159, '710005500': 160, '710005601': 161, '710005602': 162, '710005701': 163, '710005702': 164, '710005800': 165, '710005901': 166, '710005902': 167, '710005903': 168, '710006000': 169, '710006100': 170, '710006200': 171, '710006400': 172, '710006501': 173, '710006502': 174, '710006601': 175, '710006602': 176, '710006603': 177, '710006604': 178, '710006605': 179, '710006606': 180, '710006607': 181, '710006800': 182, '710006901': 183, '710006902': 184, '710007001': 185, '710007002': 186, '043010100': 187, '191010100': 188, '027010100': 189, '165010100': 190, '089010100': 191, '009010100': 192, '003010100': 193, '775010100': 194, '143010100': 195, '193010100': 196, '750010101': 197, '750010102': 198, '650010103': 199, '179010103': 200, '650010104': 201, '179010105': 202, '179010106': 203, '179010107': 204, '179010108': 205, '760010200': 206, '750010200': 207, '193010200': 208, '009010200': 209, '043010200': 210, '191010200': 211, '165010200': 212, '027010200': 213, '775010200': 214, '143010200': 215, '650010200': 216, '089010200': 217, '003010201': 218, '179010201': 219, '003010202': 220, '179010202': 221, '179010204': 222, '179010205': 223, '179010206': 224, '179010207': 225, '179010210': 226, '179010211': 227, '179010212': 228, '179010213': 229, '179010214': 230, '143010300': 231, '775010300': 232, '191010300': 233, '193010300': 234, '760010300': 235, '003010300': 236, '043010300': 237, '009010300': 238, '089010300': 239, '165010300': 240, '027010300': 241, '179010301': 242, '179010303': 243, '179010304': 244, '650010304': 245, '179010305': 246, '650010306': 247, '650010307': 248, '650010309': 249, '650010310': 250, '650010311': 251, '650010312': 252, '650010313': 253, '650010314': 254, '165010400': 255, '650010400': 256, '143010400': 257, '193010400': 258, '027010400': 259, '089010400': 260, '009010401': 261, '191010401': 262, '760010401': 263, '003010401': 264, '003010402': 265, '191010402': 266, '009010402': 267, '760010402': 268, '179010403': 269, '179010404': 270, '179010405': 271, '179010406': 272, '760010500': 273, '089010500': 274, '165010500': 275, '143010500': 276, '027010500': 277, '003010500': 278, '775010501': 279, '650010501': 280, '191010501': 281, '650010502': 282, '191010502': 283, '009010502': 284, '179010502': 285, '775010502': 286, '009010503': 287, '179010503': 288, '009010504': 289, '179010504': 290, '165010600': 291, '760010600': 292, '009010600': 293, '143010600': 294, '027010600': 295, '191010601': 296, '650010601': 297, '089010601': 298, '003010601': 299, '003010602': 300, '650010602': 301, '191010602': 302, '089010602': 303, '191010700': 304, '089010700': 305, '027010700': 306, '165010700': 307, '143010700': 308, '003010700': 309, '760010700': 310, '650010701': 311, '650010702': 312, '650010703': 313, '760010800': 314, '650010800': 315, '003010800': 316, '089010800': 317, '165010800': 318, '191010800': 319, '143010801': 320, '143010802': 321, '165010900': 322, '650010900': 323, '191010900': 324, '760010900': 325, '089010900': 326, '143010900': 327, '003010901': 328, '003010902': 329, '003010903': 330, '003011000': 331, '165011000': 332, '760011000': 333, '650011000': 334, '191011000': 335, '089011000': 336, '143011001': 337, '143011002': 338, '760011100': 339, '143011100': 340, '003011100': 341, '650011100': 342, '089011100': 343, '165011100': 344, '143011200': 345, '089011200': 346, '165011200': 347, '650011200': 348, '003011201': 349, '003011202': 350, '143011300': 351, '650011300': 352, '089011300': 353, '003011301': 354, '003011302': 355, '003011303': 356, '650011400': 357, '143011400': 358, '003011400': 359, '165011400': 360, '650011500': 361, '165011500': 362, '165011600': 363, '650011600': 364, '165011700': 365, '165011800': 366, '650011800': 367, '650011900': 368, '165011900': 369, '650012000': 370, '165012000': 371, '650012100': 372, '550020001': 373, '550020002': 374, '550020003': 375, '187020100': 376, '760020100': 377, '133020100': 378, '550020100': 379, '185020100': 380, '121020100': 381, '520020100': 382, '065020101': 383, '067020101': 384, '031020101': 385, '065020102': 386, '067020102': 387, '031020102': 388, '177020104': 389, '177020105': 390, '177020106': 391, '177020107': 392, '177020108': 393, '177020109': 394, '177020110': 395, '177020111': 396, '177020112': 397, '177020113': 398, '177020114': 399, '760020200': 400, '031020200': 401, '067020200': 402, '187020200': 403, '520020200': 404, '065020200': 405, '133020200': 406, '550020200': 407, '185020200': 408, '121020201': 409, '177020201': 410, '177020202': 411, '121020202': 412, '177020203': 413, '177020204': 414, '177020205': 415, '520020300': 416, '121020300': 417, '760020300': 418, '133020300': 419, '067020300': 420, '185020300': 421, '065020300': 422, '187020300': 423, '031020300': 424, '550020300': 425, '177020304': 426, '177020305': 427, '177020306': 428, '177020307': 429, '177020308': 430, '177020309': 431, '177020310': 432, '177020311': 433, '067020400': 434, '550020400': 435, '520020400': 436, '121020400': 437, '185020400': 438, '187020400': 439, '760020400': 440, '031020401': 441, '031020402': 442, '177020403': 443, '031020403': 444, '177020404': 445, '177020405': 446, '177020406': 447, '177020407': 448, '177020408': 449, '031020500': 450, '187020500': 451, '121020500': 452, '760020500': 453, '550020500': 454, '185020500': 455, '067020500': 456, '550020600': 457, '067020600': 458, '760020600': 459, '121020600': 460, '031020600': 461, '185020600': 462, '187020601': 463, '187020602': 464, '760020700': 465, '185020700': 466, '550020700': 467, '031020700': 468, '187020700': 469, '121020700': 470, '067020700': 471, '067020800': 472, '185020800': 473, '121020800': 474, '760020800': 475, '031020800': 476, '550020804': 477, '550020805': 478, '550020806': 479, '550020807': 480, '550020808': 481, '550020809': 482, '121020900': 483, '185020900': 484, '067020900': 485, '760020900': 486, '031020900': 487, '550020903': 488, '550020904': 489, '550020905': 490, '550020906': 491, '185021000': 492, '121021000': 493, '760021000': 494, '550021004': 495, '550021005': 496, '550021006': 497, '550021009': 498, '550021010': 499, '550021011': 500, '550021012': 501, '550021013': 502, '121021100': 503, '185021100': 504, '760021100': 505, '550021101': 506, '550021102': 507, '550021200': 508, '121021200': 509, '760021200': 510, '121021300': 511, '550021301': 512, '550021302': 513, '121021400': 514, '550021401': 515, '550021402': 516, '550021403': 517, '550021404': 518, '121021500': 519, '550021501': 520, '550021502': 521, '550021601': 522, '550021602': 523, '033030100': 524, '173030100': 525, '141030100': 526, '169030100': 527, '161030100': 528, '139030100': 529, '760030100': 530, '167030100': 531, '700030100': 532, '103030100': 533, '019030101': 534, '079030101': 535, '079030102': 536, '019030103': 537, '019030104': 538, '173030200': 539, '079030200': 540, '103030200': 541, '167030200': 542, '169030200': 543, '139030200': 544, '141030200': 545, '760030200': 546, '161030201': 547, '033030201': 548, '019030201': 549, '033030202': 550, '019030202': 551, '161030203': 552, '161030204': 553, '161030205': 554, '161030300': 555, '139030300': 556, '169030300': 557, '167030300': 558, '700030300': 559, '019030300': 560, '033030300': 561, '103030300': 562, '141030301': 563, '173030301': 564, '173030302': 565, '141030302': 566, '139030400': 567, '033030400': 568, '169030400': 569, '700030400': 570, '173030400': 571, '167030401': 572, '019030401': 573, '019030402': 574, '167030402': 575, '161030500': 576, '760030500': 577, '033030500': 578, '167030500': 579, '173030500': 580, '139030500': 581, '169030500': 582, '700030500': 583, '019030501': 584, '019030503': 585, '019030504': 586, '700030600': 587, '033030600': 588, '173030600': 589, '169030600': 590, '167030600': 591, '161030600': 592, '019030601': 593, '019030602': 594, '019030603': 595, '019030604': 596, '019030605': 597, '173030701': 598, '161030701': 599, '173030702': 600, '161030702': 601, '700030800': 602, '161030801': 603, '161030802': 604, '161030900': 605, '700030900': 606, '161031000': 607, '700031100': 608, '161031101': 609, '161031102': 610, '700031200': 611, '161031201': 612, '161031202': 613, '700031300': 614, '700031400': 615, '700031500': 616, '700031601': 617, '700031602': 618, '700031701': 619, '700031702': 620, '700031800': 621, '700031901': 622, '700031902': 623, '700032001': 624, '700032002': 625, '700032005': 626, '700032006': 627, '700032007': 628, '700032113': 629, '700032114': 630, '700032117': 631, '700032123': 632, '700032124': 633, '700032126': 634, '700032127': 635, '700032128': 636, '700032129': 637, '700032130': 638, '700032131': 639, '700032132': 640, '700032211': 641, '700032212': 642, '700032223': 643, '700032224': 644, '700032225': 645, '700032226': 646, '700032300': 647, '700032400': 648, '810040000': 649, '099040100': 650, '011040100': 651, '023040100': 652, '021040100': 653, '159040100': 654, '171040100': 655, '051040100': 656, '023040200': 657, '011040200': 658, '021040200': 659, '760040200': 660, '810040200': 661, '159040200': 662, '051040200': 663, '099040200': 664, '171040201': 665, '171040202': 666, '011040300': 667, '760040300': 668, '099040300': 669, '051040300': 670, '171040300': 671, '023040301': 672, '023040302': 673, '051040400': 674, '099040400': 675, '171040400': 676, '760040400': 677, '023040401': 678, '810040402': 679, '023040402': 680, '810040403': 681, '810040404': 682, '171040500': 683, '099040500': 684, '760040500': 685, '023040501': 686, '023040502': 687, '810040600': 688, '171040600': 689, '760040600': 690, '171040700': 691, '760040700': 692, '171040800': 693, '760040800': 694, '810040801': 695, '810040802': 696, '760040900': 697, '760041000': 698, '810041002': 699, '810041003': 700, '810041004': 701, '760041100': 702, '810041200': 703, '760041200': 704, '760041300': 705, '760041400': 706, '810041400': 707, '810041600': 708, '760041600': 709, '810041801': 710, '810041802': 711, '810042000': 712, '810042201': 713, '810042202': 714, '810042400': 715, '810042600': 716, '810042801': 717, '810042802': 718, '810043002': 719, '810043003': 720, '810043004': 721, '810043200': 722, '810043400': 723, '810043600': 724, '810043800': 725, '810044001': 726, '810044003': 727, '810044004': 728, '810044200': 729, '810044401': 730, '810044402': 731, '810044600': 732, '810044805': 733, '810044806': 734, '810044807': 735, '810044808': 736, '810045000': 737, '810045200': 738, '810045405': 739, '810045406': 740, '810045407': 741, '810045408': 742, '810045412': 743, '810045414': 744, '810045415': 745, '810045417': 746, '810045420': 747, '810045421': 748, '810045422': 749, '810045423': 750, '810045424': 751, '810045425': 752, '810045426': 753, '810045427': 754, '810045428': 755, '810045601': 756, '810045603': 757, '810045604': 758, '810045801': 759, '810045803': 760, '810045805': 761, '810045806': 762, '810045807': 763, '810045808': 764, '810045809': 765, '810045810': 766, '810046002': 767, '810046005': 768, '810046006': 769, '810046009': 770, '810046010': 771, '810046011': 772, '810046012': 773, '810046013': 774, '810046014': 775, '810046015': 776, '810046016': 777, '810046204': 778, '810046206': 779, '810046207': 780, '810046211': 781, '810046212': 782, '810046213': 783, '810046214': 784, '810046216': 785, '810046217': 786, '810046219': 787, '810046220': 788, '810046221': 789, '810046222': 790, '810046223': 791, '810046224': 792, '810046225': 793, '810046400': 794, '197050100': 795, '069050100': 796, '045050100': 797, '760050100': 798, '019050100': 799, '197050200': 800, '069050200': 801, '760050200': 802, '199050203': 803, '199050204': 804, '199050205': 805, '199050206': 806, '760050300': 807, '069050300': 808, '197050301': 809, '197050302': 810, '199050303': 811, '199050304': 812, '199050305': 813, '199050306': 814, '760050400': 815, '069050400': 816, '197050401': 817, '199050401': 818, '197050402': 819, '199050402': 820, '760050500': 821, '069050500': 822, '199050500': 823, '069050600': 824, '760050600': 825, '069050700': 826, '069050801': 827, '069050802': 828, '069050803': 829, '199050900': 830, '069050900': 831, '069051000': 832, '199051000': 833, '199051100': 834, '069051101': 835, '069051102': 836, '077060101': 838, '077060102': 839, '760060200': 841, '077060201': 842, '077060202': 843, '077060300': 844, '760060400': 845, '760060500': 846, '760060600': 847, '760060700': 848, '760060800': 849, '760060900': 850, '760061000': 851, '800065100': 852, '800065200': 853, '800065300': 854, '800065400': 855, '800065500': 856, '005070100': 857, '760070100': 858, '015070100': 859, '640070101': 860, '640070102': 861, '015070200': 862, '015070300': 863, '760070300': 864, '760070400': 865, '015070400': 866, '015070500': 867, '015070600': 868, '760070601': 869, '760070602': 870, '760070700': 871, '015070700': 872, '015070800': 873, '760070801': 874, '760070802': 875, '760070900': 876, '015070900': 877, '015071000': 878, '760071001': 879, '760071002': 880, '760071100': 881, '015071101': 882, '015071102': 883, '015071200': 884, '800075101': 885, '800075102': 886, '800075201': 887, '800075202': 888, '800075203': 889, '800075204': 890, '800075301': 891, '800075302': 892, '800075401': 893, '800075402': 894, '800075403': 895, '800075404': 896, '800075405': 897, '800075501': 898, '800075502': 899, '800075601': 900, '800075602': 901, '800075701': 902, '800075702': 903, '800075703': 904, '800075801': 905, '800075802': 906, '800075803': 907, '005080100': 908, '035080100': 909, '095080101': 910, '095080102': 911, '035080200': 912, '005080201': 913, '095080202': 914, '005080202': 915, '095080203': 916, '095080205': 917, '095080206': 918, '035080300': 919, '095080301': 920, '005080301': 921, '005080302': 922, '095080303': 923, '095080304': 924, '035080400': 925, '095080401': 926, '095080402': 927, '035080500': 928, '035080601': 929, '035080602': 930, '620090100': 931, '001090100': 932, '001090200': 933, '620090200': 934, '001090300': 935, '001090400': 936, '001090500': 937, '001090600': 938, '001090700': 939, '001090800': 940, '073100100': 941, '013100100': 942, '041100106': 943, '041100107': 944, '013100200': 945, '073100201': 946, '073100202': 947, '073100203': 948, '041100205': 949, '041100206': 950, '041100208': 951, '041100209': 952, '041100210': 953, '013100300': 954, '041100300': 955, '073100301': 956, '073100302': 957, '013100400': 958, '073100400': 959, '041100403': 960, '041100404': 961, '041100405': 962, '041100406': 963, '041100407': 964, '041100409': 965, '041100410': 966, '013100500': 967, '073100500': 968, '041100505': 969, '041100506': 970, '041100507': 971, '041100508': 972, '041100509': 973, '041100510': 974, '013100600': 975, '041100600': 976, '013100700': 977, '041100701': 978, '041100702': 979, '041100703': 980, '013100800': 981, '041100804': 982, '041100805': 983, '041100806': 984, '041100807': 985, '041100812': 986, '041100814': 987, '041100815': 988, '041100816': 989, '041100817': 990, '041100818': 991, '041100819': 992, '041100820': 993, '041100821': 994, '041100822': 995, '041100823': 996, '013100900': 997, '041100902': 998, '041100907': 999, '041100910': 1000, '041100912': 1001, '041100915': 1002, '041100919': 1003, '041100920': 1004, '041100921': 1005, '041100922': 1006, '041100923': 1007, '041100924': 1008, '041100926': 1009, '041100927': 1010, '041100928': 1011, '041100929': 1012, '041100930': 1013, '041100931': 1014, '041100932': 1015, '041100933': 1016, '041100934': 1017, '041100935': 1018, '041100936': 1019, '013101000': 1020, '041101003': 1021, '041101004': 1022, '041101007': 1023, '041101008': 1024, '041101009': 1025, '041101010': 1026, '041101011': 1027, '041101012': 1028, '041101013': 1029, '013101100': 1030, '013101200': 1031, '013101300': 1032, '013101401': 1033, '013101402': 1034, '013101403': 1035, '013101404': 1036, '013101500': 1037, '013101601': 1038, '013101602': 1039, '013101603': 1040, '013101701': 1041, '013101702': 1042, '013101703': 1043, '013101801': 1044, '013101802': 1045, '013101803': 1046, '013101900': 1047, '013102001': 1048, '013102002': 1049, '013102003': 1050, '013102100': 1051, '013102200': 1052, '013102301': 1053, '013102302': 1054, '013102400': 1055, '013102500': 1056, '013102600': 1057, '013102701': 1058, '013102702': 1059, '013102801': 1060, '013102802': 1061, '013102901': 1062, '013102902': 1063, '013103000': 1064, '013103100': 1065, '013103200': 1066, '013103300': 1067, '013103401': 1068, '013103402': 1069, '013103501': 1070, '013103502': 1071, '013103503': 1072, '013103601': 1073, '013103602': 1074, '013103700': 1075, '013103800': 1076, '137110102': 1077, '137110103': 1078, '137110104': 1079, '137110200': 1080, '137110300': 1081, '175200100': 1082, '510200102': 1083, '510200103': 1084, '087200104': 1085, '510200104': 1086, '510200105': 1087, '087200105': 1088, '510200106': 1089, '087200106': 1090, '510200107': 1091, '087200107': 1092, '087200108': 1093, '087200109': 1094, '087200112': 1095, '087200116': 1096, '087200119': 1097, '087200120': 1098, '087200121': 1099, '087200122': 1100, '087200123': 1101, '087200124': 1102, '087200125': 1103, '087200126': 1104, '087200127': 1105, '087200128': 1106, '087200129': 1107, '087200130': 1108, '175200200': 1109, '087200201': 1110, '510200201': 1111, '087200202': 1112, '510200202': 1113, '175200300': 1114, '087200301': 1115, '510200301': 1116, '510200302': 1117, '087200302': 1118, '510200303': 1119, '087200303': 1120, '087200305': 1121, '175200400': 1122, '510200403': 1123, '510200404': 1124, '087200404': 1125, '510200405': 1126, '510200406': 1127, '087200406': 1128, '510200407': 1129, '087200407': 1130, '087200409': 1131, '087200410': 1132, '087200411': 1133, '087200412': 1134, '087200413': 1135, '087200414': 1136, '510200500': 1137, '175200500': 1138, '087200501': 1139, '087200502': 1140, '087200503': 1141, '510200600': 1142, '087200600': 1143, '087200700': 1144, '510200701': 1145, '510200702': 1146, '510200703': 1147, '087200801': 1148, '510200801': 1149, '087200802': 1150, '510200802': 1151, '087200804': 1152, '087200805': 1153, '510200900': 1154, '087200903': 1155, '087200904': 1156, '087200905': 1157, '087200906': 1158, '510201000': 1159, '087201001': 1160, '087201002': 1161, '087201003': 1162, '510201100': 1163, '087201101': 1164, '087201102': 1165, '087201201': 1166, '087201202': 1167, '510201202': 1168, '510201203': 1169, '510201204': 1170, '510201300': 1171, '510201400': 1172, '087201401': 1173, '087201403': 1174, '087201404': 1175, '510201500': 1176, '087201501': 1177, '087201502': 1178, '510201600': 1179, '087201601': 1180, '087201602': 1181, '087201701': 1182, '510201801': 1183, '510201802': 1184, '510201900': 1185, '510202001': 1186, '510202002': 1187, '155210100': 1188, '740210200': 1189, '155210201': 1190, '155210202': 1191, '740210300': 1192, '155210300': 1193, '155210400': 1194, '740210400': 1195, '155210500': 1196, '740210500': 1197, '155210600': 1198, '740210600': 1199, '155210700': 1200, '740210900': 1201, '740211100': 1202, '740211400': 1203, '740211500': 1204, '740211600': 1205, '740211700': 1206, '740211800': 1207, '740211900': 1208, '740212000': 1209, '740212100': 1210, '740212300': 1211, '740212400': 1212, '740212500': 1213, '740212600': 1214, '740212701': 1215, '740212702': 1216, '740212801': 1217, '740212802': 1218, '740212900': 1219, '740213001': 1220, '740213002': 1221, '740213101': 1222, '740213103': 1223, '740213104': 1224, '740213200': 1225, '093280101': 1226, '093280103': 1227, '093280104': 1228, '093280105': 1229, '093280106': 1230, '093280200': 1231, '093280300': 1232, '093280400': 1233, '085320100': 1239, '085320200': 1240, '085320300': 1241, '085320400': 1242, '085320500': 1243, '085320601': 1244, '085320602': 1245, '085320701': 1246, '085320702': 1247, '085320801': 1248, '085320803': 1249, '085320804': 1250, '085320805': 1251, '085320900': 1252, '085321001': 1253, '085321002': 1254, '085321100': 1255, '085321201': 1256, '085321202': 1257, '085321300': 1258, '085321401': 1259, '085321402': 1260, '085321403': 1261, '735340100': 1262, '735340200': 1263, '735340300': 1264, '830370100': 1265, '830370200': 1266, '830370300': 1267, '075400100': 1268, '075400200': 1269, '075400300': 1270, '075400400': 1271, '075400500': 1272, '059415100': 1273, '059415200': 1274, '059415300': 1275, '059415401': 1276, '059415402': 1277, '059415500': 1278, '059415600': 1279, '059415700': 1280, '059415800': 1281, '059415900': 1282, '059416000': 1283, '059416100': 1284, '059416200': 1285, '059416300': 1286, '059420100': 1287, '059420201': 1288, '059420202': 1289, '059420203': 1290, '059420300': 1291, '059420400': 1292, '059420501': 1293, '059420502': 1294, '059420503': 1295, '059420600': 1296, '059420700': 1297, '059420800': 1298, '059421001': 1299, '059421002': 1300, '059421101': 1301, '059421102': 1302, '059421103': 1303, '059421200': 1304, '059421300': 1305, '059421400': 1306, '059421500': 1307, '059421600': 1308, '059421701': 1309, '059421702': 1310, '059421800': 1311, '059421900': 1312, '059422000': 1313, '059422101': 1314, '059422102': 1315, '059422201': 1316, '059422202': 1317, '059422301': 1318, '059422302': 1319, '059422401': 1320, '059422402': 1321, '059422403': 1322, '059430101': 1323, '059430102': 1324, '059430201': 1325, '059430202': 1326, '059430203': 1327, '059430400': 1328, '059430500': 1329, '059430600': 1330, '059430700': 1331, '059430801': 1332, '059430802': 1333, '059430901': 1334, '059430902': 1335, '059431001': 1336, '059431002': 1337, '059431300': 1338, '059431400': 1339, '059431500': 1340, '059431600': 1341, '059431801': 1342, '059431802': 1343, '059431900': 1344, '059432000': 1345, '059432100': 1346, '059432201': 1347, '059432202': 1348, '059432300': 1349, '059432401': 1350, '059432402': 1351, '059432500': 1352, '059432600': 1353, '059432701': 1354, '059432702': 1355, '059432800': 1356, '059440100': 1357, '059440201': 1358, '059440202': 1359, '059440300': 1360, '059440501': 1361, '059440502': 1362, '059440600': 1363, '059440701': 1364, '059440702': 1365, '059440800': 1366, '059450100': 1367, '059450200': 1368, '059450300': 1369, '059450400': 1370, '059450500': 1371, '059450601': 1372, '059450602': 1373, '059450701': 1374, '059450702': 1375, '059450800': 1376, '059450900': 1377, '059451000': 1378, '059451100': 1379, '059451200': 1380, '059451300': 1381, '059451400': 1382, '059451501': 1383, '059451502': 1384, '059451601': 1385, '059451602': 1386, '059451800': 1387, '059451900': 1388, '059452000': 1389, '059452101': 1390, '059452102': 1391, '059452200': 1392, '059452301': 1393, '059452302': 1394, '059452400': 1395, '059452501': 1396, '059452502': 1397, '059452600': 1398, '059452700': 1399, '059452801': 1400, '059452802': 1401, '059460100': 1402, '059460200': 1403, '059460300': 1404, '059460400': 1405, '059460501': 1406, '059460502': 1407, '059460600': 1408, '059460701': 1409, '059460702': 1410, '059460800': 1411, '059460900': 1412, '059461000': 1413, '059461100': 1414, '059461201': 1415, '059461202': 1416, '059461500': 1417, '059461601': 1418, '059461602': 1419, '059461700': 1420, '059461801': 1421, '059461802': 1422, '059461901': 1423, '059461902': 1424, '059470100': 1425, '059470300': 1426, '059470400': 1427, '059470500': 1428, '059470600': 1429, '059470700': 1430, '059470800': 1431, '059470900': 1432, '059471000': 1433, '059471100': 1434, '059471201': 1435, '059471202': 1436, '059471301': 1437, '059471303': 1438, '059471304': 1439, '059471401': 1440, '059471402': 1441, '059480100': 1442, '059480201': 1443, '059480202': 1444, '059480203': 1445, '059480300': 1446, '059480401': 1447, '059480402': 1448, '059480501': 1449, '059480502': 1450, '059480503': 1451, '059480504': 1452, '059480505': 1453, '059480801': 1454, '059480802': 1455, '059480901': 1456, '059480902': 1457, '059480903': 1458, '059481000': 1459, '059481101': 1460, '059481102': 1461, '059481103': 1462, '059481104': 1463, '059481105': 1464, '059481106': 1465, '059481201': 1466, '059481202': 1467, '059481400': 1468, '059481500': 1469, '059481600': 1470, '059481701': 1471, '059481702': 1472, '059481900': 1473, '059482001': 1474, '059482002': 1475, '059482100': 1476, '059482201': 1477, '059482202': 1478, '059482203': 1479, '059482301': 1480, '059482302': 1481, '059482303': 1482, '059482400': 1483, '059482501': 1484, '059482502': 1485, '059482503': 1486, '059482504': 1487, '059482601': 1488, '059482602': 1489, '059490101': 1490, '059490103': 1491, '059490501': 1492, '059490502': 1493, '059491000': 1494, '059491101': 1495, '059491102': 1496, '059491103': 1497, '059491201': 1498, '059491202': 1499, '059491301': 1500, '059491302': 1501, '059491303': 1502, '059491401': 1503, '059491402': 1504, '059491403': 1505, '059491404': 1506, '059491405': 1507, '059491501': 1508, '059491502': 1509, '059491601': 1510, '059491602': 1511, '059491701': 1512, '059491702': 1513, '059491703': 1514, '059491704': 1515, '059491705': 1516, '059491801': 1517, '059491802': 1518, '059491803': 1519, '059492000': 1520, '059492100': 1521, '059492201': 1522, '059492202': 1523, '059492203': 1524, '059492300': 1525, '059492400': 1526, '059492500': 1527, '610500100': 1528, '145500101': 1529, '145500102': 1530, '145500200': 1531, '610500200': 1532, '610500300': 1533, '145500300': 1534, '145500400': 1535, '036600100': 1536, '036600200': 1537, '036600300': 1538, '107610101': 1539, '107610102': 1540, '107610201': 1541, '107610202': 1542, '107610300': 1543, '107610400': 1544, '107610503': 1545, '107610504': 1546, '107610505': 1547, '107610506': 1548, '107610507': 1549, '107610601': 1550, '107610602': 1551, '107610603': 1552, '107610604': 1553, '107610701': 1554, '107610702': 1555, '107610703': 1556, '107610800': 1557, '107610900': 1558, '107611002': 1559, '107611004': 1560, '107611005': 1561, '107611006': 1562, '107611009': 1563, '107611010': 1564, '107611011': 1565, '107611012': 1566, '107611013': 1567, '107611014': 1568, '107611015': 1569, '107611016': 1570, '107611017': 1571, '107611018': 1572, '107611019': 1573, '107611020': 1574, '107611021': 1575, '107611022': 1576, '107611023': 1577, '107611024': 1578, '107611025': 1579, '107611101': 1580, '107611102': 1581, '107611202': 1582, '107611204': 1583, '107611205': 1584, '107611206': 1585, '107611207': 1586, '107611208': 1587, '107611209': 1588, '107611300': 1589, '107611400': 1590, '107611501': 1591, '107611502': 1592, '107611601': 1593, '107611602': 1594, '107611700': 1595, '107611801': 1596, '107611802': 1597, '107611803': 1598, '107611804': 1599, '107611805': 1600, '107611806': 1601, '107611900': 1602, '127700100': 1603, '127700200': 1604, '127700300': 1605, '730810100': 1606, '730810300': 1607, '730810400': 1608, '730810500': 1609, '730810600': 1610, '730810700': 1611, '730810900': 1612, '730811000': 1613, '730811100': 1614, '730811200': 1615, '730811300': 1616, '670820100': 1617, '670820300': 1618, '670820400': 1619, '670820500': 1620, '670820600': 1621, '670820700': 1622, '570830100': 1623, '570830200': 1624, '570830300': 1625, '570830400': 1626, '570830500': 1627, '053840100': 1628, '053840200': 1629, '053840300': 1630, '053840400': 1631, '053840500': 1632, '053840600': 1633, '149850100': 1634, '149850200': 1635, '149850301': 1636, '149850302': 1637, '149850400': 1638, '149850501': 1639, '149850502': 1640, '181860100': 1641, '181860200': 1642, '183870100': 1643, '183870201': 1644, '183870202': 1645, '183870300': 1646, '183870400': 1647, '081880101': 1648, '081880102': 1649, '081880200': 1650, '153900100': 1653, '153900201': 1654, '153900202': 1655, '153900203': 1656, '153900300': 1657, '153900403': 1658, '153900404': 1659, '153900407': 1660, '153900408': 1661, '153900409': 1662, '153900410': 1663, '153900501': 1664, '153900502': 1665, '153900600': 1666, '153900701': 1667, '153900702': 1668, '153900801': 1669, '153900802': 1670, '153900901': 1671, '153900904': 1672, '153900905': 1673, '153901001': 1674, '153901005': 1675, '153901008': 1676, '153901009': 1677, '153901010': 1678, '153901011': 1679, '153901012': 1680, '153901100': 1681, '153901203': 1682, '153901208': 1683, '153901209': 1684, '153901211': 1685, '153901212': 1686, '153901219': 1687, '153901221': 1688, '153901222': 1689, '153901223': 1690, '153901224': 1691, '153901225': 1692, '153901226': 1693, '153901227': 1694, '153901228': 1695, '153901229': 1696, '153901230': 1697, '153901231': 1698, '153901232': 1699, '153901233': 1700, '153901234': 1701, '153901235': 1702, '153901236': 1703, '153901237': 1704, '153901303': 1705, '153901304': 1706, '153901305': 1707, '153901306': 1708, '153901403': 1709, '153901407': 1710, '153901408': 1711, '153901409': 1712, '153901410': 1713, '153901411': 1714, '153901412': 1715, '153901413': 1716, '153901414': 1717, '153901415': 1718, '153901416': 1719, '153901417': 1720, '153901503': 1721, '153901504': 1722, '153901505': 1723, '153901506': 1724, '153901507': 1725, '153901508': 1726, '153901509': 1727, '153901510': 1728, '153901511': 1729, '153901601': 1730, '153901602': 1731, '153901701': 1732, '153901702': 1733, '153901900': 1734, '683910100': 1735, '683910201': 1736, '683910202': 1737, '683910301': 1738, '683910302': 1739, '683910401': 1740, '683910402': 1741, '017920100': 1742, '063920101': 1744, '063920102': 1745, '063920200': 1747, '113930100': 1748, '111930100': 1749, '071930100': 1750, '083930100': 1751, '037930100': 1752, '049930100': 1753, '025930100': 1754, '163930100': 1755, '147930100': 1756, '007930100': 1757, '131930100': 1758, '061930100': 1759, '029930101': 1760, '117930101': 1761, '047930101': 1762, '029930102': 1763, '047930102': 1764, '117930102': 1765, '071930200': 1766, '113930200': 1767, '163930200': 1768, '111930200': 1769, '131930200': 1770, '037930200': 1771, '049930200': 1772, '117930200': 1773, '007930200': 1774, '025930201': 1775, '047930201': 1776, '083930201': 1777, '029930201': 1778, '147930201': 1779, '025930202': 1780, '083930202': 1781, '147930202': 1782, '029930202': 1783, '047930202': 1784, '025930203': 1785, '061930203': 1786, '147930203': 1787, '061930204': 1788, '061930205': 1789, '061930206': 1790, '061930207': 1791, '025930300': 1792, '117930300': 1793, '163930300': 1794, '147930300': 1795, '047930300': 1796, '071930300': 1797, '111930300': 1798, '037930300': 1799, '131930300': 1800, '083930301': 1801, '083930302': 1802, '061930302': 1803, '061930303': 1804, '061930304': 1805, '117930400': 1806, '163930400': 1807, '071930400': 1808, '047930400': 1809, '083930400': 1810, '061930401': 1811, '061930402': 1812, '061930403': 1813, '117930500': 1814, '083930500': 1816, '047930501': 1817, '047930502': 1818, '083930600': 1819, '530930600': 1820, '117930600': 1821, '117930700': 1822, '195930700': 1823, '061930703': 1824, '061930704': 1825, '061930705': 1826, '061930706': 1827, '061930707': 1828, '083930800': 1829, '195930800': 1830, '117930800': 1831, '195930900': 1832, '195931000': 1833, '195931100': 1834, '195931200': 1835, '195931300': 1836, '195931400': 1837, '195931500': 1838, '195931600': 1839, '195931700': 1840, '105950100': 1841, '109950100': 1842, '157950100': 1843, '125950100': 1844, '101950101': 1845, '101950102': 1846, '157950200': 1847, '101950200': 1848, '105950200': 1849, '125950200': 1850, '109950201': 1851, '109950202': 1852, '101950300': 1853, '105950300': 1854, '125950300': 1855, '109950300': 1856, '097950400': 1857, '105950400': 1858, '109950400': 1859, '105950500': 1860, '109950500': 1861, '097950500': 1862, '105950600': 1863, '057950600': 1864, '057950700': 1865, '057950800': 1866, '119950900': 1867, '119951000': 1868, '119951100': 1869, '119951200': 1870, '115951300': 1871, '115951400': 1872, '720960100': 1873, '091970100': 1874, '153980100': 1875, '107980100': 1876, '155980100': 1877, '087980100': 1878, '710980100': 1879, '001980100': 1880, '670980100': 1881, '059980100': 1882, '013980100': 1883, '135980100': 1884, '053980100': 1885, '590980100': 1886, '740980100': 1887, '710980200': 1888, '059980200': 1889, '155980200': 1890, '001980200': 1891, '013980200': 1892, '710980300': 1893, '059980300': 1894, '710990000': 1895, '650990100': 1896, '001990100': 1897, '103990100': 1898, '735990100': 1899, '199990100': 1900, '131990100': 1901, '133990100': 1902, '119990100': 1903, '810990100': 1904, '115990100': 1905, '001990200': 1906}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning Checking Shape:\n",
        "Life_Tract.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0YEwAaAKhW1",
        "outputId": "9591897d-d5ba-4a49-c871-2096bbfa5a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1907, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the Bad Data Points!\n",
        "Life_Tract = Life_Tract.drop(badIndexes)\n",
        "print(Life_Tract.shape)\n",
        "Life_Tract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "E9SnUOsmKjyd",
        "outputId": "5cd59bef-15aa-4edc-94c0-2b21e4ea08b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1895, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         State               County  Census Tract  Life Expectancy  \\\n",
              "1732  Virginia         Roanoke City           1.0             74.8   \n",
              "1535  Virginia         Norfolk City           1.0              NaN   \n",
              "1397  Virginia  Fredericksburg City           1.0             80.1   \n",
              "1902  Virginia      Winchester City           1.0             74.5   \n",
              "1760  Virginia        Staunton City           1.0             78.4   \n",
              "...        ...                  ...           ...              ...   \n",
              "908   Virginia       Northumberland        9901.0              NaN   \n",
              "878   Virginia            Middlesex        9901.0              NaN   \n",
              "1893  Virginia  Virginia Beach City        9901.0              NaN   \n",
              "864   Virginia              Mathews        9901.0              NaN   \n",
              "11    Virginia             Accomack        9902.0              NaN   \n",
              "\n",
              "     Life Expectancy Range  Life Expectancy Standard Error  \n",
              "1732             56.9-75.1                          1.6514  \n",
              "1535                   NaN                             NaN  \n",
              "1397             79.6-81.6                          1.5574  \n",
              "1902             56.9-75.1                          1.3690  \n",
              "1760             77.6-79.5                          1.7956  \n",
              "...                    ...                             ...  \n",
              "908                    NaN                             NaN  \n",
              "878                    NaN                             NaN  \n",
              "1893                   NaN                             NaN  \n",
              "864                    NaN                             NaN  \n",
              "11                     NaN                             NaN  \n",
              "\n",
              "[1895 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ded463d8-491d-4c21-8184-acf8ed13e73c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>County</th>\n",
              "      <th>Census Tract</th>\n",
              "      <th>Life Expectancy</th>\n",
              "      <th>Life Expectancy Range</th>\n",
              "      <th>Life Expectancy Standard Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1732</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Roanoke City</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.8</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.6514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1535</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Norfolk City</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Fredericksburg City</td>\n",
              "      <td>1.0</td>\n",
              "      <td>80.1</td>\n",
              "      <td>79.6-81.6</td>\n",
              "      <td>1.5574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1902</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Winchester City</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.5</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.3690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1760</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Staunton City</td>\n",
              "      <td>1.0</td>\n",
              "      <td>78.4</td>\n",
              "      <td>77.6-79.5</td>\n",
              "      <td>1.7956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>908</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Northumberland</td>\n",
              "      <td>9901.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Middlesex</td>\n",
              "      <td>9901.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Virginia Beach City</td>\n",
              "      <td>9901.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Mathews</td>\n",
              "      <td>9901.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Accomack</td>\n",
              "      <td>9902.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1895 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ded463d8-491d-4c21-8184-acf8ed13e73c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ded463d8-491d-4c21-8184-acf8ed13e73c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ded463d8-491d-4c21-8184-acf8ed13e73c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add GEOID column!\n",
        "Life_Tract['GEOID'] = geoids\n",
        "# Drop Census Tract here, we don't need it anymore\n",
        "Life_Tract = Life_Tract.drop(['Census Tract'], axis=1)"
      ],
      "metadata": {
        "id": "LV1p9APFKku4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check\n",
        "Life_Tract.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YfhDM07XKl0S",
        "outputId": "3bac2238-c3d3-4252-80b9-68f3746eb572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         State               County  Life Expectancy Life Expectancy Range  \\\n",
              "1732  Virginia         Roanoke City             74.8             56.9-75.1   \n",
              "1535  Virginia         Norfolk City              NaN                   NaN   \n",
              "1397  Virginia  Fredericksburg City             80.1             79.6-81.6   \n",
              "1902  Virginia      Winchester City             74.5             56.9-75.1   \n",
              "1760  Virginia        Staunton City             78.4             77.6-79.5   \n",
              "\n",
              "      Life Expectancy Standard Error      GEOID  \n",
              "1732                          1.6514  770000100  \n",
              "1535                             NaN  710000100  \n",
              "1397                          1.5574  630000100  \n",
              "1902                          1.3690  840000100  \n",
              "1760                          1.7956  790000100  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c873e216-00ee-4fa4-8707-08864545f16d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>County</th>\n",
              "      <th>Life Expectancy</th>\n",
              "      <th>Life Expectancy Range</th>\n",
              "      <th>Life Expectancy Standard Error</th>\n",
              "      <th>GEOID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1732</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Roanoke City</td>\n",
              "      <td>74.8</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.6514</td>\n",
              "      <td>770000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1535</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Norfolk City</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>710000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Fredericksburg City</td>\n",
              "      <td>80.1</td>\n",
              "      <td>79.6-81.6</td>\n",
              "      <td>1.5574</td>\n",
              "      <td>630000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1902</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Winchester City</td>\n",
              "      <td>74.5</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.3690</td>\n",
              "      <td>840000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1760</th>\n",
              "      <td>Virginia</td>\n",
              "      <td>Staunton City</td>\n",
              "      <td>78.4</td>\n",
              "      <td>77.6-79.5</td>\n",
              "      <td>1.7956</td>\n",
              "      <td>790000100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c873e216-00ee-4fa4-8707-08864545f16d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c873e216-00ee-4fa4-8707-08864545f16d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c873e216-00ee-4fa4-8707-08864545f16d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean Census Tract of HOI!\n",
        "HOI.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "Ge5kPQQtKnUv",
        "outputId": "b35dec94-42ea-4068-8b08-8b9509da1160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Census Tract Rural~Urban  Access to Care  Employment Accessibility  \\\n",
              "263   51001090100       Rural        0.273908                  0.011102   \n",
              "483   51001090200       Rural        0.273908                  0.008525   \n",
              "554   51001090300       Rural        0.277446                  0.014110   \n",
              "485   51001090400       Rural        0.555905                  0.021915   \n",
              "741   51001090500       Rural        0.555905                  0.014512   \n",
              "\n",
              "     Affordability  Air Quality  Population Churning  Education  \\\n",
              "263       0.465465     0.887563             0.912214   0.718747   \n",
              "483       0.526527     0.896792             0.949109   0.684452   \n",
              "554       0.381381     0.907006             0.949109   0.628343   \n",
              "485       0.505506     0.902609             0.895674   0.616631   \n",
              "741       0.421421     0.891768             0.989822   0.681361   \n",
              "\n",
              "     Food Accessibility  Income Inequality  Job Participation  \\\n",
              "263            0.942139           0.347638              0.588   \n",
              "483            0.942139           0.391093              0.581   \n",
              "554            0.942139           0.452362              0.614   \n",
              "485            0.942139           0.398111              0.580   \n",
              "741            0.942139           0.435358              0.607   \n",
              "\n",
              "     Population Density  Segregation  Material Deprivation  Walkability  \\\n",
              "263            0.006054     0.749077              0.413495     0.162616   \n",
              "483            0.001021     0.810144              0.516062     0.087799   \n",
              "554            0.000540     0.702573              0.410243     0.051170   \n",
              "485            0.001038     0.813625              0.292771     0.106350   \n",
              "741            0.002097     0.748832              0.308089     0.089221   \n",
              "\n",
              "     Community Environment Profile  Consumer Opportunity Profile  \\\n",
              "263                       0.321956                      0.639827   \n",
              "483                       0.271668                      0.658822   \n",
              "554                       0.254516                      0.516740   \n",
              "485                       0.302841                      0.556501   \n",
              "741                       0.282644                      0.567528   \n",
              "\n",
              "     Economic Opportunity Profile  Wellness Disparity Profile  \\\n",
              "263                      0.185053                    0.270180   \n",
              "483                      0.200148                    0.239055   \n",
              "554                      0.235381                    0.296392   \n",
              "485                      0.222238                    0.437237   \n",
              "741                      0.229408                    0.470261   \n",
              "\n",
              "     Health Opportunity Index  \n",
              "263                  0.330824  \n",
              "483                  0.370909  \n",
              "554                  0.378442  \n",
              "485                  0.371092  \n",
              "741                  0.403519  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16084d36-2164-4e95-a4c8-869e30947a80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Census Tract</th>\n",
              "      <th>Rural~Urban</th>\n",
              "      <th>Access to Care</th>\n",
              "      <th>Employment Accessibility</th>\n",
              "      <th>Affordability</th>\n",
              "      <th>Air Quality</th>\n",
              "      <th>Population Churning</th>\n",
              "      <th>Education</th>\n",
              "      <th>Food Accessibility</th>\n",
              "      <th>Income Inequality</th>\n",
              "      <th>Job Participation</th>\n",
              "      <th>Population Density</th>\n",
              "      <th>Segregation</th>\n",
              "      <th>Material Deprivation</th>\n",
              "      <th>Walkability</th>\n",
              "      <th>Community Environment Profile</th>\n",
              "      <th>Consumer Opportunity Profile</th>\n",
              "      <th>Economic Opportunity Profile</th>\n",
              "      <th>Wellness Disparity Profile</th>\n",
              "      <th>Health Opportunity Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>51001090100</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.273908</td>\n",
              "      <td>0.011102</td>\n",
              "      <td>0.465465</td>\n",
              "      <td>0.887563</td>\n",
              "      <td>0.912214</td>\n",
              "      <td>0.718747</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.347638</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.006054</td>\n",
              "      <td>0.749077</td>\n",
              "      <td>0.413495</td>\n",
              "      <td>0.162616</td>\n",
              "      <td>0.321956</td>\n",
              "      <td>0.639827</td>\n",
              "      <td>0.185053</td>\n",
              "      <td>0.270180</td>\n",
              "      <td>0.330824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>51001090200</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.273908</td>\n",
              "      <td>0.008525</td>\n",
              "      <td>0.526527</td>\n",
              "      <td>0.896792</td>\n",
              "      <td>0.949109</td>\n",
              "      <td>0.684452</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.391093</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.001021</td>\n",
              "      <td>0.810144</td>\n",
              "      <td>0.516062</td>\n",
              "      <td>0.087799</td>\n",
              "      <td>0.271668</td>\n",
              "      <td>0.658822</td>\n",
              "      <td>0.200148</td>\n",
              "      <td>0.239055</td>\n",
              "      <td>0.370909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>51001090300</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.277446</td>\n",
              "      <td>0.014110</td>\n",
              "      <td>0.381381</td>\n",
              "      <td>0.907006</td>\n",
              "      <td>0.949109</td>\n",
              "      <td>0.628343</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.452362</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.702573</td>\n",
              "      <td>0.410243</td>\n",
              "      <td>0.051170</td>\n",
              "      <td>0.254516</td>\n",
              "      <td>0.516740</td>\n",
              "      <td>0.235381</td>\n",
              "      <td>0.296392</td>\n",
              "      <td>0.378442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>51001090400</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.555905</td>\n",
              "      <td>0.021915</td>\n",
              "      <td>0.505506</td>\n",
              "      <td>0.902609</td>\n",
              "      <td>0.895674</td>\n",
              "      <td>0.616631</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.398111</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.001038</td>\n",
              "      <td>0.813625</td>\n",
              "      <td>0.292771</td>\n",
              "      <td>0.106350</td>\n",
              "      <td>0.302841</td>\n",
              "      <td>0.556501</td>\n",
              "      <td>0.222238</td>\n",
              "      <td>0.437237</td>\n",
              "      <td>0.371092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>51001090500</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.555905</td>\n",
              "      <td>0.014512</td>\n",
              "      <td>0.421421</td>\n",
              "      <td>0.891768</td>\n",
              "      <td>0.989822</td>\n",
              "      <td>0.681361</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.435358</td>\n",
              "      <td>0.607</td>\n",
              "      <td>0.002097</td>\n",
              "      <td>0.748832</td>\n",
              "      <td>0.308089</td>\n",
              "      <td>0.089221</td>\n",
              "      <td>0.282644</td>\n",
              "      <td>0.567528</td>\n",
              "      <td>0.229408</td>\n",
              "      <td>0.470261</td>\n",
              "      <td>0.403519</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16084d36-2164-4e95-a4c8-869e30947a80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16084d36-2164-4e95-a4c8-869e30947a80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16084d36-2164-4e95-a4c8-869e30947a80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Census Tract to string to remove the \"51\" on the end, also create new GEOID column to merge on in HOI dataframe\n",
        "HOI['Census Tract'] = HOI['Census Tract'].astype(str)\n",
        "HOI['GEOID'] = HOI['Census Tract'].map(lambda x: x.lstrip('51'))\n",
        "HOI.drop('Census Tract', axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "vXEAdLSnKoRt",
        "outputId": "ef1cb062-109c-4360-a4ce-85f0749349c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Rural~Urban  Access to Care  Employment Accessibility  Affordability  \\\n",
              "263       Rural        0.273908                  0.011102       0.465465   \n",
              "483       Rural        0.273908                  0.008525       0.526527   \n",
              "554       Rural        0.277446                  0.014110       0.381381   \n",
              "485       Rural        0.555905                  0.021915       0.505506   \n",
              "741       Rural        0.555905                  0.014512       0.421421   \n",
              "..          ...             ...                       ...            ...   \n",
              "95        Urban        0.435096                  0.086138       0.274274   \n",
              "723       Urban        0.435096                  0.157033       0.564565   \n",
              "693       Urban        0.435096                  0.109394       0.613614   \n",
              "365       Urban        0.435096                  0.069851       0.504505   \n",
              "431       Urban        0.439218                  0.092514       0.480480   \n",
              "\n",
              "     Air Quality  Population Churning  Education  Food Accessibility  \\\n",
              "263     0.887563             0.912214   0.718747            0.942139   \n",
              "483     0.896792             0.949109   0.684452            0.942139   \n",
              "554     0.907006             0.949109   0.628343            0.942139   \n",
              "485     0.902609             0.895674   0.616631            0.942139   \n",
              "741     0.891768             0.989822   0.681361            0.942139   \n",
              "..           ...                  ...        ...                 ...   \n",
              "95      0.653627             0.737913   0.602679            0.979340   \n",
              "723     0.770042             0.708651   0.774457            0.766586   \n",
              "693     0.758740             0.782443   0.803688            0.891328   \n",
              "365     0.752720             0.732824   0.648909            0.936152   \n",
              "431     0.763541             0.720102   0.739301            0.961922   \n",
              "\n",
              "     Income Inequality  Job Participation  Population Density  Segregation  \\\n",
              "263           0.347638              0.588            0.006054     0.749077   \n",
              "483           0.391093              0.581            0.001021     0.810144   \n",
              "554           0.452362              0.614            0.000540     0.702573   \n",
              "485           0.398111              0.580            0.001038     0.813625   \n",
              "741           0.435358              0.607            0.002097     0.748832   \n",
              "..                 ...                ...                 ...          ...   \n",
              "95            0.435628              0.671            0.064798     0.898252   \n",
              "723           0.348988              0.680            0.036447     0.735834   \n",
              "693           0.371795              0.595            0.049587     0.735834   \n",
              "365           0.493117              0.636            0.050741     0.735834   \n",
              "431           0.403374              0.620            0.027825     0.735834   \n",
              "\n",
              "     Material Deprivation  Walkability  Community Environment Profile  \\\n",
              "263              0.413495     0.162616                       0.321956   \n",
              "483              0.516062     0.087799                       0.271668   \n",
              "554              0.410243     0.051170                       0.254516   \n",
              "485              0.292771     0.106350                       0.302841   \n",
              "741              0.308089     0.089221                       0.282644   \n",
              "..                    ...          ...                            ...   \n",
              "95               0.201041     0.246344                       0.459465   \n",
              "723              0.473983     0.181110                       0.394476   \n",
              "693              0.522296     0.236572                       0.393562   \n",
              "365              0.303825     0.251226                       0.404216   \n",
              "431              0.359770     0.174608                       0.393369   \n",
              "\n",
              "     Consumer Opportunity Profile  Economic Opportunity Profile  \\\n",
              "263                      0.639827                      0.185053   \n",
              "483                      0.658822                      0.200148   \n",
              "554                      0.516740                      0.235381   \n",
              "485                      0.556501                      0.222238   \n",
              "741                      0.567528                      0.229408   \n",
              "..                            ...                           ...   \n",
              "95                       0.424871                      0.274488   \n",
              "723                      0.547955                      0.312852   \n",
              "693                      0.702260                      0.254909   \n",
              "365                      0.530829                      0.282053   \n",
              "431                      0.600940                      0.253060   \n",
              "\n",
              "     Wellness Disparity Profile  Health Opportunity Index      GEOID  \n",
              "263                    0.270180                  0.330824  001090100  \n",
              "483                    0.239055                  0.370909  001090200  \n",
              "554                    0.296392                  0.378442  001090300  \n",
              "485                    0.437237                  0.371092  001090400  \n",
              "741                    0.470261                  0.403519  001090500  \n",
              "..                          ...                       ...        ...  \n",
              "95                     0.308441                  0.269371  840000100  \n",
              "723                    0.391224                  0.400053  840000201  \n",
              "693                    0.391224                  0.395440  840000202  \n",
              "365                    0.391224                  0.349738  840000301  \n",
              "431                    0.394146                  0.360501  840000302  \n",
              "\n",
              "[1875 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81d69229-3bff-4a80-a22f-216e6bd800ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rural~Urban</th>\n",
              "      <th>Access to Care</th>\n",
              "      <th>Employment Accessibility</th>\n",
              "      <th>Affordability</th>\n",
              "      <th>Air Quality</th>\n",
              "      <th>Population Churning</th>\n",
              "      <th>Education</th>\n",
              "      <th>Food Accessibility</th>\n",
              "      <th>Income Inequality</th>\n",
              "      <th>Job Participation</th>\n",
              "      <th>Population Density</th>\n",
              "      <th>Segregation</th>\n",
              "      <th>Material Deprivation</th>\n",
              "      <th>Walkability</th>\n",
              "      <th>Community Environment Profile</th>\n",
              "      <th>Consumer Opportunity Profile</th>\n",
              "      <th>Economic Opportunity Profile</th>\n",
              "      <th>Wellness Disparity Profile</th>\n",
              "      <th>Health Opportunity Index</th>\n",
              "      <th>GEOID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>Rural</td>\n",
              "      <td>0.273908</td>\n",
              "      <td>0.011102</td>\n",
              "      <td>0.465465</td>\n",
              "      <td>0.887563</td>\n",
              "      <td>0.912214</td>\n",
              "      <td>0.718747</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.347638</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.006054</td>\n",
              "      <td>0.749077</td>\n",
              "      <td>0.413495</td>\n",
              "      <td>0.162616</td>\n",
              "      <td>0.321956</td>\n",
              "      <td>0.639827</td>\n",
              "      <td>0.185053</td>\n",
              "      <td>0.270180</td>\n",
              "      <td>0.330824</td>\n",
              "      <td>001090100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>Rural</td>\n",
              "      <td>0.273908</td>\n",
              "      <td>0.008525</td>\n",
              "      <td>0.526527</td>\n",
              "      <td>0.896792</td>\n",
              "      <td>0.949109</td>\n",
              "      <td>0.684452</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.391093</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.001021</td>\n",
              "      <td>0.810144</td>\n",
              "      <td>0.516062</td>\n",
              "      <td>0.087799</td>\n",
              "      <td>0.271668</td>\n",
              "      <td>0.658822</td>\n",
              "      <td>0.200148</td>\n",
              "      <td>0.239055</td>\n",
              "      <td>0.370909</td>\n",
              "      <td>001090200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>Rural</td>\n",
              "      <td>0.277446</td>\n",
              "      <td>0.014110</td>\n",
              "      <td>0.381381</td>\n",
              "      <td>0.907006</td>\n",
              "      <td>0.949109</td>\n",
              "      <td>0.628343</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.452362</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.702573</td>\n",
              "      <td>0.410243</td>\n",
              "      <td>0.051170</td>\n",
              "      <td>0.254516</td>\n",
              "      <td>0.516740</td>\n",
              "      <td>0.235381</td>\n",
              "      <td>0.296392</td>\n",
              "      <td>0.378442</td>\n",
              "      <td>001090300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>Rural</td>\n",
              "      <td>0.555905</td>\n",
              "      <td>0.021915</td>\n",
              "      <td>0.505506</td>\n",
              "      <td>0.902609</td>\n",
              "      <td>0.895674</td>\n",
              "      <td>0.616631</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.398111</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.001038</td>\n",
              "      <td>0.813625</td>\n",
              "      <td>0.292771</td>\n",
              "      <td>0.106350</td>\n",
              "      <td>0.302841</td>\n",
              "      <td>0.556501</td>\n",
              "      <td>0.222238</td>\n",
              "      <td>0.437237</td>\n",
              "      <td>0.371092</td>\n",
              "      <td>001090400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>Rural</td>\n",
              "      <td>0.555905</td>\n",
              "      <td>0.014512</td>\n",
              "      <td>0.421421</td>\n",
              "      <td>0.891768</td>\n",
              "      <td>0.989822</td>\n",
              "      <td>0.681361</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.435358</td>\n",
              "      <td>0.607</td>\n",
              "      <td>0.002097</td>\n",
              "      <td>0.748832</td>\n",
              "      <td>0.308089</td>\n",
              "      <td>0.089221</td>\n",
              "      <td>0.282644</td>\n",
              "      <td>0.567528</td>\n",
              "      <td>0.229408</td>\n",
              "      <td>0.470261</td>\n",
              "      <td>0.403519</td>\n",
              "      <td>001090500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Urban</td>\n",
              "      <td>0.435096</td>\n",
              "      <td>0.086138</td>\n",
              "      <td>0.274274</td>\n",
              "      <td>0.653627</td>\n",
              "      <td>0.737913</td>\n",
              "      <td>0.602679</td>\n",
              "      <td>0.979340</td>\n",
              "      <td>0.435628</td>\n",
              "      <td>0.671</td>\n",
              "      <td>0.064798</td>\n",
              "      <td>0.898252</td>\n",
              "      <td>0.201041</td>\n",
              "      <td>0.246344</td>\n",
              "      <td>0.459465</td>\n",
              "      <td>0.424871</td>\n",
              "      <td>0.274488</td>\n",
              "      <td>0.308441</td>\n",
              "      <td>0.269371</td>\n",
              "      <td>840000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>Urban</td>\n",
              "      <td>0.435096</td>\n",
              "      <td>0.157033</td>\n",
              "      <td>0.564565</td>\n",
              "      <td>0.770042</td>\n",
              "      <td>0.708651</td>\n",
              "      <td>0.774457</td>\n",
              "      <td>0.766586</td>\n",
              "      <td>0.348988</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.036447</td>\n",
              "      <td>0.735834</td>\n",
              "      <td>0.473983</td>\n",
              "      <td>0.181110</td>\n",
              "      <td>0.394476</td>\n",
              "      <td>0.547955</td>\n",
              "      <td>0.312852</td>\n",
              "      <td>0.391224</td>\n",
              "      <td>0.400053</td>\n",
              "      <td>840000201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>Urban</td>\n",
              "      <td>0.435096</td>\n",
              "      <td>0.109394</td>\n",
              "      <td>0.613614</td>\n",
              "      <td>0.758740</td>\n",
              "      <td>0.782443</td>\n",
              "      <td>0.803688</td>\n",
              "      <td>0.891328</td>\n",
              "      <td>0.371795</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.049587</td>\n",
              "      <td>0.735834</td>\n",
              "      <td>0.522296</td>\n",
              "      <td>0.236572</td>\n",
              "      <td>0.393562</td>\n",
              "      <td>0.702260</td>\n",
              "      <td>0.254909</td>\n",
              "      <td>0.391224</td>\n",
              "      <td>0.395440</td>\n",
              "      <td>840000202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>Urban</td>\n",
              "      <td>0.435096</td>\n",
              "      <td>0.069851</td>\n",
              "      <td>0.504505</td>\n",
              "      <td>0.752720</td>\n",
              "      <td>0.732824</td>\n",
              "      <td>0.648909</td>\n",
              "      <td>0.936152</td>\n",
              "      <td>0.493117</td>\n",
              "      <td>0.636</td>\n",
              "      <td>0.050741</td>\n",
              "      <td>0.735834</td>\n",
              "      <td>0.303825</td>\n",
              "      <td>0.251226</td>\n",
              "      <td>0.404216</td>\n",
              "      <td>0.530829</td>\n",
              "      <td>0.282053</td>\n",
              "      <td>0.391224</td>\n",
              "      <td>0.349738</td>\n",
              "      <td>840000301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>Urban</td>\n",
              "      <td>0.439218</td>\n",
              "      <td>0.092514</td>\n",
              "      <td>0.480480</td>\n",
              "      <td>0.763541</td>\n",
              "      <td>0.720102</td>\n",
              "      <td>0.739301</td>\n",
              "      <td>0.961922</td>\n",
              "      <td>0.403374</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.027825</td>\n",
              "      <td>0.735834</td>\n",
              "      <td>0.359770</td>\n",
              "      <td>0.174608</td>\n",
              "      <td>0.393369</td>\n",
              "      <td>0.600940</td>\n",
              "      <td>0.253060</td>\n",
              "      <td>0.394146</td>\n",
              "      <td>0.360501</td>\n",
              "      <td>840000302</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1875 rows Ã— 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81d69229-3bff-4a80-a22f-216e6bd800ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81d69229-3bff-4a80-a22f-216e6bd800ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81d69229-3bff-4a80-a22f-216e6bd800ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify\n",
        "HOI.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "139YMBs1Ku3_",
        "outputId": "dc775c2e-8455-4b8a-8d2b-4de755df0664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Census Tract Rural~Urban  Access to Care  Employment Accessibility  \\\n",
              "263  51001090100       Rural        0.273908                  0.011102   \n",
              "483  51001090200       Rural        0.273908                  0.008525   \n",
              "554  51001090300       Rural        0.277446                  0.014110   \n",
              "485  51001090400       Rural        0.555905                  0.021915   \n",
              "741  51001090500       Rural        0.555905                  0.014512   \n",
              "\n",
              "     Affordability  Air Quality  Population Churning  Education  \\\n",
              "263       0.465465     0.887563             0.912214   0.718747   \n",
              "483       0.526527     0.896792             0.949109   0.684452   \n",
              "554       0.381381     0.907006             0.949109   0.628343   \n",
              "485       0.505506     0.902609             0.895674   0.616631   \n",
              "741       0.421421     0.891768             0.989822   0.681361   \n",
              "\n",
              "     Food Accessibility  Income Inequality  ...  Population Density  \\\n",
              "263            0.942139           0.347638  ...            0.006054   \n",
              "483            0.942139           0.391093  ...            0.001021   \n",
              "554            0.942139           0.452362  ...            0.000540   \n",
              "485            0.942139           0.398111  ...            0.001038   \n",
              "741            0.942139           0.435358  ...            0.002097   \n",
              "\n",
              "     Segregation  Material Deprivation  Walkability  \\\n",
              "263     0.749077              0.413495     0.162616   \n",
              "483     0.810144              0.516062     0.087799   \n",
              "554     0.702573              0.410243     0.051170   \n",
              "485     0.813625              0.292771     0.106350   \n",
              "741     0.748832              0.308089     0.089221   \n",
              "\n",
              "     Community Environment Profile  Consumer Opportunity Profile  \\\n",
              "263                       0.321956                      0.639827   \n",
              "483                       0.271668                      0.658822   \n",
              "554                       0.254516                      0.516740   \n",
              "485                       0.302841                      0.556501   \n",
              "741                       0.282644                      0.567528   \n",
              "\n",
              "     Economic Opportunity Profile  Wellness Disparity Profile  \\\n",
              "263                      0.185053                    0.270180   \n",
              "483                      0.200148                    0.239055   \n",
              "554                      0.235381                    0.296392   \n",
              "485                      0.222238                    0.437237   \n",
              "741                      0.229408                    0.470261   \n",
              "\n",
              "     Health Opportunity Index      GEOID  \n",
              "263                  0.330824  001090100  \n",
              "483                  0.370909  001090200  \n",
              "554                  0.378442  001090300  \n",
              "485                  0.371092  001090400  \n",
              "741                  0.403519  001090500  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7124ca3c-ebde-4629-8185-2e63400e4ea1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Census Tract</th>\n",
              "      <th>Rural~Urban</th>\n",
              "      <th>Access to Care</th>\n",
              "      <th>Employment Accessibility</th>\n",
              "      <th>Affordability</th>\n",
              "      <th>Air Quality</th>\n",
              "      <th>Population Churning</th>\n",
              "      <th>Education</th>\n",
              "      <th>Food Accessibility</th>\n",
              "      <th>Income Inequality</th>\n",
              "      <th>...</th>\n",
              "      <th>Population Density</th>\n",
              "      <th>Segregation</th>\n",
              "      <th>Material Deprivation</th>\n",
              "      <th>Walkability</th>\n",
              "      <th>Community Environment Profile</th>\n",
              "      <th>Consumer Opportunity Profile</th>\n",
              "      <th>Economic Opportunity Profile</th>\n",
              "      <th>Wellness Disparity Profile</th>\n",
              "      <th>Health Opportunity Index</th>\n",
              "      <th>GEOID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>51001090100</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.273908</td>\n",
              "      <td>0.011102</td>\n",
              "      <td>0.465465</td>\n",
              "      <td>0.887563</td>\n",
              "      <td>0.912214</td>\n",
              "      <td>0.718747</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.347638</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006054</td>\n",
              "      <td>0.749077</td>\n",
              "      <td>0.413495</td>\n",
              "      <td>0.162616</td>\n",
              "      <td>0.321956</td>\n",
              "      <td>0.639827</td>\n",
              "      <td>0.185053</td>\n",
              "      <td>0.270180</td>\n",
              "      <td>0.330824</td>\n",
              "      <td>001090100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>51001090200</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.273908</td>\n",
              "      <td>0.008525</td>\n",
              "      <td>0.526527</td>\n",
              "      <td>0.896792</td>\n",
              "      <td>0.949109</td>\n",
              "      <td>0.684452</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.391093</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001021</td>\n",
              "      <td>0.810144</td>\n",
              "      <td>0.516062</td>\n",
              "      <td>0.087799</td>\n",
              "      <td>0.271668</td>\n",
              "      <td>0.658822</td>\n",
              "      <td>0.200148</td>\n",
              "      <td>0.239055</td>\n",
              "      <td>0.370909</td>\n",
              "      <td>001090200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>51001090300</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.277446</td>\n",
              "      <td>0.014110</td>\n",
              "      <td>0.381381</td>\n",
              "      <td>0.907006</td>\n",
              "      <td>0.949109</td>\n",
              "      <td>0.628343</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.452362</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.702573</td>\n",
              "      <td>0.410243</td>\n",
              "      <td>0.051170</td>\n",
              "      <td>0.254516</td>\n",
              "      <td>0.516740</td>\n",
              "      <td>0.235381</td>\n",
              "      <td>0.296392</td>\n",
              "      <td>0.378442</td>\n",
              "      <td>001090300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>51001090400</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.555905</td>\n",
              "      <td>0.021915</td>\n",
              "      <td>0.505506</td>\n",
              "      <td>0.902609</td>\n",
              "      <td>0.895674</td>\n",
              "      <td>0.616631</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.398111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001038</td>\n",
              "      <td>0.813625</td>\n",
              "      <td>0.292771</td>\n",
              "      <td>0.106350</td>\n",
              "      <td>0.302841</td>\n",
              "      <td>0.556501</td>\n",
              "      <td>0.222238</td>\n",
              "      <td>0.437237</td>\n",
              "      <td>0.371092</td>\n",
              "      <td>001090400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>51001090500</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.555905</td>\n",
              "      <td>0.014512</td>\n",
              "      <td>0.421421</td>\n",
              "      <td>0.891768</td>\n",
              "      <td>0.989822</td>\n",
              "      <td>0.681361</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.435358</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002097</td>\n",
              "      <td>0.748832</td>\n",
              "      <td>0.308089</td>\n",
              "      <td>0.089221</td>\n",
              "      <td>0.282644</td>\n",
              "      <td>0.567528</td>\n",
              "      <td>0.229408</td>\n",
              "      <td>0.470261</td>\n",
              "      <td>0.403519</td>\n",
              "      <td>001090500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7124ca3c-ebde-4629-8185-2e63400e4ea1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7124ca3c-ebde-4629-8185-2e63400e4ea1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7124ca3c-ebde-4629-8185-2e63400e4ea1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.merge(HOI, Life_Tract, on='GEOID', how='inner')"
      ],
      "metadata": {
        "id": "f4e7KHKFKw4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final Combined Data Shape: \", data.shape)\n",
        "# Look at the data\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "rjIlUCZxLC99",
        "outputId": "e3aa0487-cbe7-4e93-da35-7ce6291ab34e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Combined Data Shape:  (1262, 26)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Census Tract Rural~Urban  Access to Care  Employment Accessibility  \\\n",
              "0  51001090100       Rural        0.273908                  0.011102   \n",
              "1  51001090200       Rural        0.273908                  0.008525   \n",
              "2  51001090300       Rural        0.277446                  0.014110   \n",
              "3  51001090400       Rural        0.555905                  0.021915   \n",
              "4  51001090500       Rural        0.555905                  0.014512   \n",
              "\n",
              "   Affordability  Air Quality  Population Churning  Education  \\\n",
              "0       0.465465     0.887563             0.912214   0.718747   \n",
              "1       0.526527     0.896792             0.949109   0.684452   \n",
              "2       0.381381     0.907006             0.949109   0.628343   \n",
              "3       0.505506     0.902609             0.895674   0.616631   \n",
              "4       0.421421     0.891768             0.989822   0.681361   \n",
              "\n",
              "   Food Accessibility  Income Inequality  ...  Consumer Opportunity Profile  \\\n",
              "0            0.942139           0.347638  ...                      0.639827   \n",
              "1            0.942139           0.391093  ...                      0.658822   \n",
              "2            0.942139           0.452362  ...                      0.516740   \n",
              "3            0.942139           0.398111  ...                      0.556501   \n",
              "4            0.942139           0.435358  ...                      0.567528   \n",
              "\n",
              "   Economic Opportunity Profile  Wellness Disparity Profile  \\\n",
              "0                      0.185053                    0.270180   \n",
              "1                      0.200148                    0.239055   \n",
              "2                      0.235381                    0.296392   \n",
              "3                      0.222238                    0.437237   \n",
              "4                      0.229408                    0.470261   \n",
              "\n",
              "   Health Opportunity Index      GEOID     State         County  \\\n",
              "0                  0.330824  001090100  Virginia       Accomack   \n",
              "1                  0.370909  001090200  Virginia  Franklin City   \n",
              "2                  0.378442  001090300  Virginia       Accomack   \n",
              "3                  0.371092  001090400  Virginia       Accomack   \n",
              "4                  0.403519  001090500  Virginia       Accomack   \n",
              "\n",
              "   Life Expectancy  Life Expectancy Range  Life Expectancy Standard Error  \n",
              "0             77.5              75.2-77.5                          1.1577  \n",
              "1             71.5              56.9-75.1                          0.9309  \n",
              "2             77.7              77.6-79.5                          1.2010  \n",
              "3             73.1              56.9-75.1                          2.2543  \n",
              "4             77.0              75.2-77.5                          1.6637  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f25d3134-dcb8-4360-885e-ebe82cf71710\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Census Tract</th>\n",
              "      <th>Rural~Urban</th>\n",
              "      <th>Access to Care</th>\n",
              "      <th>Employment Accessibility</th>\n",
              "      <th>Affordability</th>\n",
              "      <th>Air Quality</th>\n",
              "      <th>Population Churning</th>\n",
              "      <th>Education</th>\n",
              "      <th>Food Accessibility</th>\n",
              "      <th>Income Inequality</th>\n",
              "      <th>...</th>\n",
              "      <th>Consumer Opportunity Profile</th>\n",
              "      <th>Economic Opportunity Profile</th>\n",
              "      <th>Wellness Disparity Profile</th>\n",
              "      <th>Health Opportunity Index</th>\n",
              "      <th>GEOID</th>\n",
              "      <th>State</th>\n",
              "      <th>County</th>\n",
              "      <th>Life Expectancy</th>\n",
              "      <th>Life Expectancy Range</th>\n",
              "      <th>Life Expectancy Standard Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51001090100</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.273908</td>\n",
              "      <td>0.011102</td>\n",
              "      <td>0.465465</td>\n",
              "      <td>0.887563</td>\n",
              "      <td>0.912214</td>\n",
              "      <td>0.718747</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.347638</td>\n",
              "      <td>...</td>\n",
              "      <td>0.639827</td>\n",
              "      <td>0.185053</td>\n",
              "      <td>0.270180</td>\n",
              "      <td>0.330824</td>\n",
              "      <td>001090100</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Accomack</td>\n",
              "      <td>77.5</td>\n",
              "      <td>75.2-77.5</td>\n",
              "      <td>1.1577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51001090200</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.273908</td>\n",
              "      <td>0.008525</td>\n",
              "      <td>0.526527</td>\n",
              "      <td>0.896792</td>\n",
              "      <td>0.949109</td>\n",
              "      <td>0.684452</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.391093</td>\n",
              "      <td>...</td>\n",
              "      <td>0.658822</td>\n",
              "      <td>0.200148</td>\n",
              "      <td>0.239055</td>\n",
              "      <td>0.370909</td>\n",
              "      <td>001090200</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Franklin City</td>\n",
              "      <td>71.5</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>0.9309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>51001090300</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.277446</td>\n",
              "      <td>0.014110</td>\n",
              "      <td>0.381381</td>\n",
              "      <td>0.907006</td>\n",
              "      <td>0.949109</td>\n",
              "      <td>0.628343</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.452362</td>\n",
              "      <td>...</td>\n",
              "      <td>0.516740</td>\n",
              "      <td>0.235381</td>\n",
              "      <td>0.296392</td>\n",
              "      <td>0.378442</td>\n",
              "      <td>001090300</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Accomack</td>\n",
              "      <td>77.7</td>\n",
              "      <td>77.6-79.5</td>\n",
              "      <td>1.2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>51001090400</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.555905</td>\n",
              "      <td>0.021915</td>\n",
              "      <td>0.505506</td>\n",
              "      <td>0.902609</td>\n",
              "      <td>0.895674</td>\n",
              "      <td>0.616631</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.398111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556501</td>\n",
              "      <td>0.222238</td>\n",
              "      <td>0.437237</td>\n",
              "      <td>0.371092</td>\n",
              "      <td>001090400</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Accomack</td>\n",
              "      <td>73.1</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>2.2543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>51001090500</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0.555905</td>\n",
              "      <td>0.014512</td>\n",
              "      <td>0.421421</td>\n",
              "      <td>0.891768</td>\n",
              "      <td>0.989822</td>\n",
              "      <td>0.681361</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.435358</td>\n",
              "      <td>...</td>\n",
              "      <td>0.567528</td>\n",
              "      <td>0.229408</td>\n",
              "      <td>0.470261</td>\n",
              "      <td>0.403519</td>\n",
              "      <td>001090500</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Accomack</td>\n",
              "      <td>77.0</td>\n",
              "      <td>75.2-77.5</td>\n",
              "      <td>1.6637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f25d3134-dcb8-4360-885e-ebe82cf71710')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f25d3134-dcb8-4360-885e-ebe82cf71710 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f25d3134-dcb8-4360-885e-ebe82cf71710');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Census Tract since we only needed it for GEOID calculation!\n",
        "data.drop('Census Tract', axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "_Ts9xkm1LQmC",
        "outputId": "b286f732-4abf-45f4-e618-bdae023944e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Rural~Urban  Access to Care  Employment Accessibility  Affordability  \\\n",
              "0          Rural        0.273908                  0.011102       0.465465   \n",
              "1          Rural        0.273908                  0.008525       0.526527   \n",
              "2          Rural        0.277446                  0.014110       0.381381   \n",
              "3          Rural        0.555905                  0.021915       0.505506   \n",
              "4          Rural        0.555905                  0.014512       0.421421   \n",
              "...          ...             ...                       ...            ...   \n",
              "1257       Urban        0.435096                  0.086138       0.274274   \n",
              "1258       Urban        0.435096                  0.157033       0.564565   \n",
              "1259       Urban        0.435096                  0.109394       0.613614   \n",
              "1260       Urban        0.435096                  0.069851       0.504505   \n",
              "1261       Urban        0.439218                  0.092514       0.480480   \n",
              "\n",
              "      Air Quality  Population Churning  Education  Food Accessibility  \\\n",
              "0        0.887563             0.912214   0.718747            0.942139   \n",
              "1        0.896792             0.949109   0.684452            0.942139   \n",
              "2        0.907006             0.949109   0.628343            0.942139   \n",
              "3        0.902609             0.895674   0.616631            0.942139   \n",
              "4        0.891768             0.989822   0.681361            0.942139   \n",
              "...           ...                  ...        ...                 ...   \n",
              "1257     0.653627             0.737913   0.602679            0.979340   \n",
              "1258     0.770042             0.708651   0.774457            0.766586   \n",
              "1259     0.758740             0.782443   0.803688            0.891328   \n",
              "1260     0.752720             0.732824   0.648909            0.936152   \n",
              "1261     0.763541             0.720102   0.739301            0.961922   \n",
              "\n",
              "      Income Inequality  Job Participation  ...  Consumer Opportunity Profile  \\\n",
              "0              0.347638              0.588  ...                      0.639827   \n",
              "1              0.391093              0.581  ...                      0.658822   \n",
              "2              0.452362              0.614  ...                      0.516740   \n",
              "3              0.398111              0.580  ...                      0.556501   \n",
              "4              0.435358              0.607  ...                      0.567528   \n",
              "...                 ...                ...  ...                           ...   \n",
              "1257           0.435628              0.671  ...                      0.424871   \n",
              "1258           0.348988              0.680  ...                      0.547955   \n",
              "1259           0.371795              0.595  ...                      0.702260   \n",
              "1260           0.493117              0.636  ...                      0.530829   \n",
              "1261           0.403374              0.620  ...                      0.600940   \n",
              "\n",
              "      Economic Opportunity Profile  Wellness Disparity Profile  \\\n",
              "0                         0.185053                    0.270180   \n",
              "1                         0.200148                    0.239055   \n",
              "2                         0.235381                    0.296392   \n",
              "3                         0.222238                    0.437237   \n",
              "4                         0.229408                    0.470261   \n",
              "...                            ...                         ...   \n",
              "1257                      0.274488                    0.308441   \n",
              "1258                      0.312852                    0.391224   \n",
              "1259                      0.254909                    0.391224   \n",
              "1260                      0.282053                    0.391224   \n",
              "1261                      0.253060                    0.394146   \n",
              "\n",
              "      Health Opportunity Index      GEOID     State           County  \\\n",
              "0                     0.330824  001090100  Virginia         Accomack   \n",
              "1                     0.370909  001090200  Virginia    Franklin City   \n",
              "2                     0.378442  001090300  Virginia         Accomack   \n",
              "3                     0.371092  001090400  Virginia         Accomack   \n",
              "4                     0.403519  001090500  Virginia         Accomack   \n",
              "...                        ...        ...       ...              ...   \n",
              "1257                  0.269371  840000100  Virginia  Winchester City   \n",
              "1258                  0.400053  840000201  Virginia  Winchester City   \n",
              "1259                  0.395440  840000202  Virginia  Winchester City   \n",
              "1260                  0.349738  840000301  Virginia  Winchester City   \n",
              "1261                  0.360501  840000302  Virginia  Winchester City   \n",
              "\n",
              "      Life Expectancy  Life Expectancy Range Life Expectancy Standard Error  \n",
              "0                77.5              75.2-77.5                         1.1577  \n",
              "1                71.5              56.9-75.1                         0.9309  \n",
              "2                77.7              77.6-79.5                         1.2010  \n",
              "3                73.1              56.9-75.1                         2.2543  \n",
              "4                77.0              75.2-77.5                         1.6637  \n",
              "...               ...                    ...                            ...  \n",
              "1257             74.5              56.9-75.1                         1.3690  \n",
              "1258             82.2              81.7-97.5                         2.0388  \n",
              "1259             82.8              81.7-97.5                         1.5941  \n",
              "1260             72.9              56.9-75.1                         1.3280  \n",
              "1261             77.4              75.2-77.5                         1.2386  \n",
              "\n",
              "[1262 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b61dedc-6749-40c9-914b-deebaf47e97b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rural~Urban</th>\n",
              "      <th>Access to Care</th>\n",
              "      <th>Employment Accessibility</th>\n",
              "      <th>Affordability</th>\n",
              "      <th>Air Quality</th>\n",
              "      <th>Population Churning</th>\n",
              "      <th>Education</th>\n",
              "      <th>Food Accessibility</th>\n",
              "      <th>Income Inequality</th>\n",
              "      <th>Job Participation</th>\n",
              "      <th>...</th>\n",
              "      <th>Consumer Opportunity Profile</th>\n",
              "      <th>Economic Opportunity Profile</th>\n",
              "      <th>Wellness Disparity Profile</th>\n",
              "      <th>Health Opportunity Index</th>\n",
              "      <th>GEOID</th>\n",
              "      <th>State</th>\n",
              "      <th>County</th>\n",
              "      <th>Life Expectancy</th>\n",
              "      <th>Life Expectancy Range</th>\n",
              "      <th>Life Expectancy Standard Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rural</td>\n",
              "      <td>0.273908</td>\n",
              "      <td>0.011102</td>\n",
              "      <td>0.465465</td>\n",
              "      <td>0.887563</td>\n",
              "      <td>0.912214</td>\n",
              "      <td>0.718747</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.347638</td>\n",
              "      <td>0.588</td>\n",
              "      <td>...</td>\n",
              "      <td>0.639827</td>\n",
              "      <td>0.185053</td>\n",
              "      <td>0.270180</td>\n",
              "      <td>0.330824</td>\n",
              "      <td>001090100</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Accomack</td>\n",
              "      <td>77.5</td>\n",
              "      <td>75.2-77.5</td>\n",
              "      <td>1.1577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rural</td>\n",
              "      <td>0.273908</td>\n",
              "      <td>0.008525</td>\n",
              "      <td>0.526527</td>\n",
              "      <td>0.896792</td>\n",
              "      <td>0.949109</td>\n",
              "      <td>0.684452</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.391093</td>\n",
              "      <td>0.581</td>\n",
              "      <td>...</td>\n",
              "      <td>0.658822</td>\n",
              "      <td>0.200148</td>\n",
              "      <td>0.239055</td>\n",
              "      <td>0.370909</td>\n",
              "      <td>001090200</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Franklin City</td>\n",
              "      <td>71.5</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>0.9309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rural</td>\n",
              "      <td>0.277446</td>\n",
              "      <td>0.014110</td>\n",
              "      <td>0.381381</td>\n",
              "      <td>0.907006</td>\n",
              "      <td>0.949109</td>\n",
              "      <td>0.628343</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.452362</td>\n",
              "      <td>0.614</td>\n",
              "      <td>...</td>\n",
              "      <td>0.516740</td>\n",
              "      <td>0.235381</td>\n",
              "      <td>0.296392</td>\n",
              "      <td>0.378442</td>\n",
              "      <td>001090300</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Accomack</td>\n",
              "      <td>77.7</td>\n",
              "      <td>77.6-79.5</td>\n",
              "      <td>1.2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rural</td>\n",
              "      <td>0.555905</td>\n",
              "      <td>0.021915</td>\n",
              "      <td>0.505506</td>\n",
              "      <td>0.902609</td>\n",
              "      <td>0.895674</td>\n",
              "      <td>0.616631</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.398111</td>\n",
              "      <td>0.580</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556501</td>\n",
              "      <td>0.222238</td>\n",
              "      <td>0.437237</td>\n",
              "      <td>0.371092</td>\n",
              "      <td>001090400</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Accomack</td>\n",
              "      <td>73.1</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>2.2543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rural</td>\n",
              "      <td>0.555905</td>\n",
              "      <td>0.014512</td>\n",
              "      <td>0.421421</td>\n",
              "      <td>0.891768</td>\n",
              "      <td>0.989822</td>\n",
              "      <td>0.681361</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.435358</td>\n",
              "      <td>0.607</td>\n",
              "      <td>...</td>\n",
              "      <td>0.567528</td>\n",
              "      <td>0.229408</td>\n",
              "      <td>0.470261</td>\n",
              "      <td>0.403519</td>\n",
              "      <td>001090500</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Accomack</td>\n",
              "      <td>77.0</td>\n",
              "      <td>75.2-77.5</td>\n",
              "      <td>1.6637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>Urban</td>\n",
              "      <td>0.435096</td>\n",
              "      <td>0.086138</td>\n",
              "      <td>0.274274</td>\n",
              "      <td>0.653627</td>\n",
              "      <td>0.737913</td>\n",
              "      <td>0.602679</td>\n",
              "      <td>0.979340</td>\n",
              "      <td>0.435628</td>\n",
              "      <td>0.671</td>\n",
              "      <td>...</td>\n",
              "      <td>0.424871</td>\n",
              "      <td>0.274488</td>\n",
              "      <td>0.308441</td>\n",
              "      <td>0.269371</td>\n",
              "      <td>840000100</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Winchester City</td>\n",
              "      <td>74.5</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.3690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>Urban</td>\n",
              "      <td>0.435096</td>\n",
              "      <td>0.157033</td>\n",
              "      <td>0.564565</td>\n",
              "      <td>0.770042</td>\n",
              "      <td>0.708651</td>\n",
              "      <td>0.774457</td>\n",
              "      <td>0.766586</td>\n",
              "      <td>0.348988</td>\n",
              "      <td>0.680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.547955</td>\n",
              "      <td>0.312852</td>\n",
              "      <td>0.391224</td>\n",
              "      <td>0.400053</td>\n",
              "      <td>840000201</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Winchester City</td>\n",
              "      <td>82.2</td>\n",
              "      <td>81.7-97.5</td>\n",
              "      <td>2.0388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1259</th>\n",
              "      <td>Urban</td>\n",
              "      <td>0.435096</td>\n",
              "      <td>0.109394</td>\n",
              "      <td>0.613614</td>\n",
              "      <td>0.758740</td>\n",
              "      <td>0.782443</td>\n",
              "      <td>0.803688</td>\n",
              "      <td>0.891328</td>\n",
              "      <td>0.371795</td>\n",
              "      <td>0.595</td>\n",
              "      <td>...</td>\n",
              "      <td>0.702260</td>\n",
              "      <td>0.254909</td>\n",
              "      <td>0.391224</td>\n",
              "      <td>0.395440</td>\n",
              "      <td>840000202</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Winchester City</td>\n",
              "      <td>82.8</td>\n",
              "      <td>81.7-97.5</td>\n",
              "      <td>1.5941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>Urban</td>\n",
              "      <td>0.435096</td>\n",
              "      <td>0.069851</td>\n",
              "      <td>0.504505</td>\n",
              "      <td>0.752720</td>\n",
              "      <td>0.732824</td>\n",
              "      <td>0.648909</td>\n",
              "      <td>0.936152</td>\n",
              "      <td>0.493117</td>\n",
              "      <td>0.636</td>\n",
              "      <td>...</td>\n",
              "      <td>0.530829</td>\n",
              "      <td>0.282053</td>\n",
              "      <td>0.391224</td>\n",
              "      <td>0.349738</td>\n",
              "      <td>840000301</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Winchester City</td>\n",
              "      <td>72.9</td>\n",
              "      <td>56.9-75.1</td>\n",
              "      <td>1.3280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1261</th>\n",
              "      <td>Urban</td>\n",
              "      <td>0.439218</td>\n",
              "      <td>0.092514</td>\n",
              "      <td>0.480480</td>\n",
              "      <td>0.763541</td>\n",
              "      <td>0.720102</td>\n",
              "      <td>0.739301</td>\n",
              "      <td>0.961922</td>\n",
              "      <td>0.403374</td>\n",
              "      <td>0.620</td>\n",
              "      <td>...</td>\n",
              "      <td>0.600940</td>\n",
              "      <td>0.253060</td>\n",
              "      <td>0.394146</td>\n",
              "      <td>0.360501</td>\n",
              "      <td>840000302</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Winchester City</td>\n",
              "      <td>77.4</td>\n",
              "      <td>75.2-77.5</td>\n",
              "      <td>1.2386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1262 rows Ã— 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b61dedc-6749-40c9-914b-deebaf47e97b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b61dedc-6749-40c9-914b-deebaf47e97b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b61dedc-6749-40c9-914b-deebaf47e97b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data info summary, look at all the features and whether they are numerical or categorical\n",
        "HOI.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtIF2M2WtuYS",
        "outputId": "7592bb6a-1586-4e2c-a57f-20631a04b84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1875 entries, 263 to 431\n",
            "Data columns (total 21 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   Census Tract                   1875 non-null   object \n",
            " 1   Rural~Urban                    1875 non-null   object \n",
            " 2   Access to Care                 1875 non-null   float64\n",
            " 3   Employment Accessibility       1875 non-null   float64\n",
            " 4   Affordability                  1875 non-null   float64\n",
            " 5   Air Quality                    1875 non-null   float64\n",
            " 6   Population Churning            1875 non-null   float64\n",
            " 7   Education                      1875 non-null   float64\n",
            " 8   Food Accessibility             1875 non-null   float64\n",
            " 9   Income Inequality              1875 non-null   float64\n",
            " 10  Job Participation              1875 non-null   float64\n",
            " 11  Population Density             1875 non-null   float64\n",
            " 12  Segregation                    1875 non-null   float64\n",
            " 13  Material Deprivation           1875 non-null   float64\n",
            " 14  Walkability                    1875 non-null   float64\n",
            " 15  Community Environment Profile  1875 non-null   float64\n",
            " 16  Consumer Opportunity Profile   1875 non-null   float64\n",
            " 17  Economic Opportunity Profile   1875 non-null   float64\n",
            " 18  Wellness Disparity Profile     1875 non-null   float64\n",
            " 19  Health Opportunity Index       1875 non-null   float64\n",
            " 20  GEOID                          1875 non-null   object \n",
            "dtypes: float64(18), object(3)\n",
            "memory usage: 322.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistics about numerical features of the dataset\n",
        "HOI.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "OusU2V_tt2U8",
        "outputId": "91324dbb-f250-4866-dd43-6dcbb7f19e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Access to Care  Employment Accessibility  Affordability  Air Quality  \\\n",
              "count     1875.000000               1875.000000    1875.000000  1875.000000   \n",
              "mean         0.430293                  0.100788       0.541067     0.826108   \n",
              "std          0.122966                  0.040566       0.130588     0.109615   \n",
              "min          0.000000                  0.000000       0.000000     0.000000   \n",
              "25%          0.363984                  0.084459       0.473473     0.764383   \n",
              "50%          0.458326                  0.105232       0.558559     0.850917   \n",
              "75%          0.502987                  0.121596       0.636637     0.904748   \n",
              "max          1.000000                  0.696429       0.827828     1.000000   \n",
              "\n",
              "       Population Churning    Education  Food Accessibility  \\\n",
              "count          1875.000000  1875.000000         1875.000000   \n",
              "mean              0.821509     0.738404            0.932584   \n",
              "std               0.125996     0.079122            0.074521   \n",
              "min               0.022901     0.000000            0.313483   \n",
              "25%               0.768448     0.681429            0.933302   \n",
              "50%               0.853690     0.730412            0.942139   \n",
              "75%               0.908397     0.792474            0.976872   \n",
              "max               1.000000     1.000000            1.000000   \n",
              "\n",
              "       Income Inequality  Job Participation  Population Density  Segregation  \\\n",
              "count        1875.000000        1875.000000         1875.000000  1875.000000   \n",
              "mean            0.467536           0.659006            0.043494     0.735817   \n",
              "std             0.088873           0.113889            0.066599     0.172272   \n",
              "min             0.000000           0.000000            0.000001     0.000000   \n",
              "25%             0.415655           0.599000            0.003532     0.668347   \n",
              "50%             0.475169           0.667000            0.027831     0.760790   \n",
              "75%             0.529150           0.735000            0.055554     0.847383   \n",
              "max             0.907557           1.000000            1.000000     1.000000   \n",
              "\n",
              "       Material Deprivation  Walkability  Community Environment Profile  \\\n",
              "count           1875.000000  1875.000000                    1875.000000   \n",
              "mean               0.456662     0.183523                       0.351329   \n",
              "std                0.142174     0.106976                       0.089182   \n",
              "min                0.000000     0.000678                       0.000000   \n",
              "25%                0.366538     0.105048                       0.284778   \n",
              "50%                0.457951     0.166149                       0.334323   \n",
              "75%                0.551325     0.252531                       0.402707   \n",
              "max                1.000000     1.000000                       1.000000   \n",
              "\n",
              "       Consumer Opportunity Profile  Economic Opportunity Profile  \\\n",
              "count                   1875.000000                   1875.000000   \n",
              "mean                       0.620942                      0.296378   \n",
              "std                        0.131028                      0.060072   \n",
              "min                        0.000000                      0.006034   \n",
              "25%                        0.546642                      0.260002   \n",
              "50%                        0.622990                      0.303343   \n",
              "75%                        0.709174                      0.336892   \n",
              "max                        1.000000                      0.867737   \n",
              "\n",
              "       Wellness Disparity Profile  Health Opportunity Index  \n",
              "count                 1875.000000               1875.000000  \n",
              "mean                     0.387827                  0.422507  \n",
              "std                      0.124507                  0.089592  \n",
              "min                      0.000000                  0.000000  \n",
              "25%                      0.312137                  0.368180  \n",
              "50%                      0.383706                  0.427082  \n",
              "75%                      0.456334                  0.483719  \n",
              "max                      1.000000                  0.728815  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53196ce8-9372-4d2e-a60a-1803db69a5c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Access to Care</th>\n",
              "      <th>Employment Accessibility</th>\n",
              "      <th>Affordability</th>\n",
              "      <th>Air Quality</th>\n",
              "      <th>Population Churning</th>\n",
              "      <th>Education</th>\n",
              "      <th>Food Accessibility</th>\n",
              "      <th>Income Inequality</th>\n",
              "      <th>Job Participation</th>\n",
              "      <th>Population Density</th>\n",
              "      <th>Segregation</th>\n",
              "      <th>Material Deprivation</th>\n",
              "      <th>Walkability</th>\n",
              "      <th>Community Environment Profile</th>\n",
              "      <th>Consumer Opportunity Profile</th>\n",
              "      <th>Economic Opportunity Profile</th>\n",
              "      <th>Wellness Disparity Profile</th>\n",
              "      <th>Health Opportunity Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>1875.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.430293</td>\n",
              "      <td>0.100788</td>\n",
              "      <td>0.541067</td>\n",
              "      <td>0.826108</td>\n",
              "      <td>0.821509</td>\n",
              "      <td>0.738404</td>\n",
              "      <td>0.932584</td>\n",
              "      <td>0.467536</td>\n",
              "      <td>0.659006</td>\n",
              "      <td>0.043494</td>\n",
              "      <td>0.735817</td>\n",
              "      <td>0.456662</td>\n",
              "      <td>0.183523</td>\n",
              "      <td>0.351329</td>\n",
              "      <td>0.620942</td>\n",
              "      <td>0.296378</td>\n",
              "      <td>0.387827</td>\n",
              "      <td>0.422507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.122966</td>\n",
              "      <td>0.040566</td>\n",
              "      <td>0.130588</td>\n",
              "      <td>0.109615</td>\n",
              "      <td>0.125996</td>\n",
              "      <td>0.079122</td>\n",
              "      <td>0.074521</td>\n",
              "      <td>0.088873</td>\n",
              "      <td>0.113889</td>\n",
              "      <td>0.066599</td>\n",
              "      <td>0.172272</td>\n",
              "      <td>0.142174</td>\n",
              "      <td>0.106976</td>\n",
              "      <td>0.089182</td>\n",
              "      <td>0.131028</td>\n",
              "      <td>0.060072</td>\n",
              "      <td>0.124507</td>\n",
              "      <td>0.089592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022901</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.313483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000678</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.363984</td>\n",
              "      <td>0.084459</td>\n",
              "      <td>0.473473</td>\n",
              "      <td>0.764383</td>\n",
              "      <td>0.768448</td>\n",
              "      <td>0.681429</td>\n",
              "      <td>0.933302</td>\n",
              "      <td>0.415655</td>\n",
              "      <td>0.599000</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>0.668347</td>\n",
              "      <td>0.366538</td>\n",
              "      <td>0.105048</td>\n",
              "      <td>0.284778</td>\n",
              "      <td>0.546642</td>\n",
              "      <td>0.260002</td>\n",
              "      <td>0.312137</td>\n",
              "      <td>0.368180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.458326</td>\n",
              "      <td>0.105232</td>\n",
              "      <td>0.558559</td>\n",
              "      <td>0.850917</td>\n",
              "      <td>0.853690</td>\n",
              "      <td>0.730412</td>\n",
              "      <td>0.942139</td>\n",
              "      <td>0.475169</td>\n",
              "      <td>0.667000</td>\n",
              "      <td>0.027831</td>\n",
              "      <td>0.760790</td>\n",
              "      <td>0.457951</td>\n",
              "      <td>0.166149</td>\n",
              "      <td>0.334323</td>\n",
              "      <td>0.622990</td>\n",
              "      <td>0.303343</td>\n",
              "      <td>0.383706</td>\n",
              "      <td>0.427082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.502987</td>\n",
              "      <td>0.121596</td>\n",
              "      <td>0.636637</td>\n",
              "      <td>0.904748</td>\n",
              "      <td>0.908397</td>\n",
              "      <td>0.792474</td>\n",
              "      <td>0.976872</td>\n",
              "      <td>0.529150</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>0.055554</td>\n",
              "      <td>0.847383</td>\n",
              "      <td>0.551325</td>\n",
              "      <td>0.252531</td>\n",
              "      <td>0.402707</td>\n",
              "      <td>0.709174</td>\n",
              "      <td>0.336892</td>\n",
              "      <td>0.456334</td>\n",
              "      <td>0.483719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.696429</td>\n",
              "      <td>0.827828</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.907557</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.867737</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.728815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53196ce8-9372-4d2e-a60a-1803db69a5c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53196ce8-9372-4d2e-a60a-1803db69a5c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53196ce8-9372-4d2e-a60a-1803db69a5c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HOI.isnull()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "ctsMjvpUt3q5",
        "outputId": "2b4d3c29-8d04-4496-b8c8-d6d095fa1f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Census Tract  Rural~Urban  Access to Care  Employment Accessibility  \\\n",
              "263         False        False           False                     False   \n",
              "483         False        False           False                     False   \n",
              "554         False        False           False                     False   \n",
              "485         False        False           False                     False   \n",
              "741         False        False           False                     False   \n",
              "..            ...          ...             ...                       ...   \n",
              "95          False        False           False                     False   \n",
              "723         False        False           False                     False   \n",
              "693         False        False           False                     False   \n",
              "365         False        False           False                     False   \n",
              "431         False        False           False                     False   \n",
              "\n",
              "     Affordability  Air Quality  Population Churning  Education  \\\n",
              "263          False        False                False      False   \n",
              "483          False        False                False      False   \n",
              "554          False        False                False      False   \n",
              "485          False        False                False      False   \n",
              "741          False        False                False      False   \n",
              "..             ...          ...                  ...        ...   \n",
              "95           False        False                False      False   \n",
              "723          False        False                False      False   \n",
              "693          False        False                False      False   \n",
              "365          False        False                False      False   \n",
              "431          False        False                False      False   \n",
              "\n",
              "     Food Accessibility  Income Inequality  ...  Population Density  \\\n",
              "263               False              False  ...               False   \n",
              "483               False              False  ...               False   \n",
              "554               False              False  ...               False   \n",
              "485               False              False  ...               False   \n",
              "741               False              False  ...               False   \n",
              "..                  ...                ...  ...                 ...   \n",
              "95                False              False  ...               False   \n",
              "723               False              False  ...               False   \n",
              "693               False              False  ...               False   \n",
              "365               False              False  ...               False   \n",
              "431               False              False  ...               False   \n",
              "\n",
              "     Segregation  Material Deprivation  Walkability  \\\n",
              "263        False                 False        False   \n",
              "483        False                 False        False   \n",
              "554        False                 False        False   \n",
              "485        False                 False        False   \n",
              "741        False                 False        False   \n",
              "..           ...                   ...          ...   \n",
              "95         False                 False        False   \n",
              "723        False                 False        False   \n",
              "693        False                 False        False   \n",
              "365        False                 False        False   \n",
              "431        False                 False        False   \n",
              "\n",
              "     Community Environment Profile  Consumer Opportunity Profile  \\\n",
              "263                          False                         False   \n",
              "483                          False                         False   \n",
              "554                          False                         False   \n",
              "485                          False                         False   \n",
              "741                          False                         False   \n",
              "..                             ...                           ...   \n",
              "95                           False                         False   \n",
              "723                          False                         False   \n",
              "693                          False                         False   \n",
              "365                          False                         False   \n",
              "431                          False                         False   \n",
              "\n",
              "     Economic Opportunity Profile  Wellness Disparity Profile  \\\n",
              "263                         False                       False   \n",
              "483                         False                       False   \n",
              "554                         False                       False   \n",
              "485                         False                       False   \n",
              "741                         False                       False   \n",
              "..                            ...                         ...   \n",
              "95                          False                       False   \n",
              "723                         False                       False   \n",
              "693                         False                       False   \n",
              "365                         False                       False   \n",
              "431                         False                       False   \n",
              "\n",
              "     Health Opportunity Index  GEOID  \n",
              "263                     False  False  \n",
              "483                     False  False  \n",
              "554                     False  False  \n",
              "485                     False  False  \n",
              "741                     False  False  \n",
              "..                        ...    ...  \n",
              "95                      False  False  \n",
              "723                     False  False  \n",
              "693                     False  False  \n",
              "365                     False  False  \n",
              "431                     False  False  \n",
              "\n",
              "[1875 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-846cc877-afcd-499f-ac3e-daddad47ea77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Census Tract</th>\n",
              "      <th>Rural~Urban</th>\n",
              "      <th>Access to Care</th>\n",
              "      <th>Employment Accessibility</th>\n",
              "      <th>Affordability</th>\n",
              "      <th>Air Quality</th>\n",
              "      <th>Population Churning</th>\n",
              "      <th>Education</th>\n",
              "      <th>Food Accessibility</th>\n",
              "      <th>Income Inequality</th>\n",
              "      <th>...</th>\n",
              "      <th>Population Density</th>\n",
              "      <th>Segregation</th>\n",
              "      <th>Material Deprivation</th>\n",
              "      <th>Walkability</th>\n",
              "      <th>Community Environment Profile</th>\n",
              "      <th>Consumer Opportunity Profile</th>\n",
              "      <th>Economic Opportunity Profile</th>\n",
              "      <th>Wellness Disparity Profile</th>\n",
              "      <th>Health Opportunity Index</th>\n",
              "      <th>GEOID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1875 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-846cc877-afcd-499f-ac3e-daddad47ea77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-846cc877-afcd-499f-ac3e-daddad47ea77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-846cc877-afcd-499f-ac3e-daddad47ea77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HOI.isnull().any()\n",
        "data = data.drop(['State', 'Life Expectancy Standard Error', 'Life Expectancy Range', 'GEOID', \"County\", \"Census Tract\"], axis=1)"
      ],
      "metadata": {
        "id": "v9svpXstt5sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "cat_vars = [\"Rural~Urban\"]\n",
        "print(data.columns.values)\n",
        "num_vars = list(set(data.columns.values) - set(cat_vars) - set([\"Life Expectancy\"]))\n",
        "print(num_vars)\n",
        "\n",
        "print(data.shape)\n",
        "data = data.dropna(subset=['Life Expectancy'])\n",
        "print(data.shape)\n",
        "\n",
        "data_x = data.copy()\n",
        "data_x = data_x.drop(\"Life Expectancy\", axis=1)\n",
        "\n",
        "data_y = data.copy()\n",
        "data_y = data[\"Life Expectancy\"]\n",
        "\n",
        "print(data_x.shape)\n",
        "\n",
        "\n",
        "\n",
        "# Split the data into train set (80%) and validation set (20%)\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(data_x, data_y, test_size=0.2, random_state=55)\n",
        "# Split validation set into testing set (10%) and validation set(10%)\n",
        "X_test, X_valid, Y_test, Y_valid = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=55)"
      ],
      "metadata": {
        "id": "KX0srCsat723",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23cee55-6d67-4809-a17d-1af556600245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Rural~Urban' 'Access to Care' 'Employment Accessibility' 'Affordability'\n",
            " 'Air Quality' 'Population Churning' 'Education' 'Food Accessibility'\n",
            " 'Income Inequality' 'Job Participation' 'Population Density'\n",
            " 'Segregation' 'Material Deprivation' 'Walkability'\n",
            " 'Community Environment Profile' 'Consumer Opportunity Profile'\n",
            " 'Economic Opportunity Profile' 'Wellness Disparity Profile'\n",
            " 'Health Opportunity Index' 'Life Expectancy']\n",
            "['Food Accessibility', 'Health Opportunity Index', 'Walkability', 'Air Quality', 'Access to Care', 'Wellness Disparity Profile', 'Income Inequality', 'Employment Accessibility', 'Population Churning', 'Community Environment Profile', 'Material Deprivation', 'Population Density', 'Consumer Opportunity Profile', 'Affordability', 'Job Participation', 'Segregation', 'Education', 'Economic Opportunity Profile']\n",
            "(1262, 20)\n",
            "(1117, 20)\n",
            "(1117, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See the shapes of each stage\n",
        "print(X_train.head())\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWaP4kIYuldt",
        "outputId": "a13b9dc1-8e16-43d7-8d52-b196079d9f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Rural~Urban  Access to Care  Employment Accessibility  Affordability  \\\n",
            "233       Urban        0.501111                  0.091191       0.651652   \n",
            "612       Rural        0.284416                  0.022983       0.302302   \n",
            "422       Urban        0.501637                  0.100682       0.725726   \n",
            "214       Urban        0.487993                  0.109434       0.619620   \n",
            "775       Urban        0.522603                  0.112742       0.577578   \n",
            "\n",
            "     Air Quality  Population Churning  Education  Food Accessibility  \\\n",
            "233     0.887514             0.853690   0.783465            0.986243   \n",
            "612     0.959823             0.935115   0.609833            0.987444   \n",
            "422     0.764272             0.922392   0.890377            0.964756   \n",
            "214     0.901588             0.893130   0.741117            0.919030   \n",
            "775     0.824784             0.754453   0.705989            0.889342   \n",
            "\n",
            "     Income Inequality  Job Participation  Population Density  Segregation  \\\n",
            "233           0.508772              0.688            0.018340     0.573937   \n",
            "612           0.300675              0.491            0.002061     0.835789   \n",
            "422           0.463833              0.630            0.014455     0.973789   \n",
            "214           0.589474              0.721            0.021313     0.587387   \n",
            "775           0.457355              0.665            0.037215     0.697353   \n",
            "\n",
            "     Material Deprivation  Walkability  Community Environment Profile  \\\n",
            "233              0.515822     0.131937                       0.291521   \n",
            "612              0.408213     0.020931                       0.266243   \n",
            "422              0.719807     0.130941                       0.317674   \n",
            "214              0.476651     0.151323                       0.278239   \n",
            "775              0.407953     0.233911                       0.372805   \n",
            "\n",
            "     Consumer Opportunity Profile  Economic Opportunity Profile  \\\n",
            "233                      0.723736                      0.300383   \n",
            "612                      0.524560                      0.170029   \n",
            "422                      0.889742                      0.271081   \n",
            "214                      0.615406                      0.359361   \n",
            "775                      0.575019                      0.311873   \n",
            "\n",
            "     Wellness Disparity Profile  Health Opportunity Index  \n",
            "233                    0.520550                  0.517318  \n",
            "612                    0.233435                  0.304357  \n",
            "422                    0.317122                  0.494933  \n",
            "214                    0.504394                  0.536852  \n",
            "775                    0.472886                  0.423651  \n",
            "(893, 19)\n",
            "(112, 19)\n",
            "(112, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "numerical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "    #('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "    (\"num\", numerical_pipeline, num_vars),\n",
        "    (\"cat\", OneHotEncoder(sparse=False), cat_vars),\n",
        "])\n",
        "\n",
        "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
        "X_val_prepared = full_pipeline.fit_transform(X_valid)\n",
        "X_test_prepared = full_pipeline.fit_transform(X_test)\n",
        "\n",
        "mySGDModel = SGDRegressor(max_iter=2000)\n",
        "\n",
        "print(full_pipeline.get_feature_names_out)\n",
        "\n",
        "param_grid = {\n",
        "    'alpha': [1, .1, .01, .001, .0001, .00001],\n",
        "    'loss': ['squared_error', 'huber', 'epsilon_insensitive'],\n",
        "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
        "    'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
        "}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TiCvxRrsu7eF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9550c67-9cae-4e8c-9e52-0cf4e628f09a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method ColumnTransformer.get_feature_names_out of ColumnTransformer(transformers=[('num',\n",
            "                                 Pipeline(steps=[('imputer',\n",
            "                                                  SimpleImputer(strategy='median'))]),\n",
            "                                 ['Food Accessibility',\n",
            "                                  'Health Opportunity Index', 'Walkability',\n",
            "                                  'Air Quality', 'Access to Care',\n",
            "                                  'Wellness Disparity Profile',\n",
            "                                  'Income Inequality',\n",
            "                                  'Employment Accessibility',\n",
            "                                  'Population Churning',\n",
            "                                  'Community Environment Profile',\n",
            "                                  'Material Deprivation', 'Population Density',\n",
            "                                  'Consumer Opportunity Profile',\n",
            "                                  'Affordability', 'Job Participation',\n",
            "                                  'Segregation', 'Education',\n",
            "                                  'Economic Opportunity Profile']),\n",
            "                                ('cat', OneHotEncoder(sparse=False),\n",
            "                                 ['Rural~Urban'])])>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gridSearch = GridSearchCV(mySGDModel, param_grid)\n",
        "print(X_train_prepared.shape)\n",
        "print(X_test_prepared.shape)\n",
        "gridSearch.fit(X_train_prepared, Y_train)\n",
        "print(gridSearch.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBkEUvteK-Zw",
        "outputId": "8f780c1d-59b9-40e3-a490-8fabd3846e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(893, 20)\n",
            "(112, 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'alpha': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error', 'penalty': 'l2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "WUdegBaVG7fH",
        "outputId": "918ebedc-84da-4685-e72f-e631c9bb59f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-e9fd3c4315f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prepared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'labels'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "y_predict = gridSearch.predict(X_test_prepared)\n",
        "\n",
        "mse = np.sqrt(mean_squared_error(Y_test, y_predict))\n",
        "print(mse)\n",
        "\n",
        "scores = cross_val_score(gridSearch, X_val_prepared, Y_valid,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
        "print(np.sqrt(-scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mYEo_fhknjo",
        "outputId": "840ca0a3-0019-478f-a39c-907dea47907e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8152296571247697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.9801606  3.77125372 4.45479983 5.68836681 3.59230684]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "\n",
        "mySVRModel = SVR(max_iter=2000)\n",
        "\n",
        "param_grid_SVR = {\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'degree': [3,4,5],\n",
        "    'C': [.1, 1, 5, 10],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "}\n",
        "\n",
        "\n",
        "gridSearchSVR = GridSearchCV(mySVRModel, param_grid_SVR)\n",
        "gridSearchSVR.fit(X_train_prepared, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPk-x5-JBjnn",
        "outputId": "8d9f6305-8f66-4346-8629-6744d1eef241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVR(max_iter=2000),\n",
              "             param_grid={'C': [0.1, 1, 5, 10], 'degree': [3, 4, 5],\n",
              "                         'gamma': ['scale', 'auto'],\n",
              "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gridSearchSVR.best_params_)\n",
        "\n",
        "y_predict_SVR = gridSearchSVR.predict(X_test_prepared)\n",
        "\n",
        "mse_SVR = np.sqrt(mean_squared_error(Y_test, y_predict_SVR))\n",
        "print(mse_SVR)\n",
        "\n",
        "scores_SVR = cross_val_score(gridSearchSVR, X_val_prepared, Y_valid,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
        "print(np.sqrt(-scores_SVR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNXX0SE9Dvjb",
        "outputId": "b71bac9c-e727-4329-cf6b-c508d506be4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 1, 'degree': 3, 'gamma': 'auto', 'kernel': 'rbf'}\n",
            "3.7630639434549766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.81018597 4.10425674 4.14651759 5.05995893 3.83497548]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['Food Accessibility',\n",
        "                                  'Health Opportunity Index', 'Walkability',\n",
        "                                  'Air Quality', 'Access to Care',\n",
        "                                  'Wellness Disparity Profile',\n",
        "                                  'Income Inequality',\n",
        "                                  'Employment Accessibility',\n",
        "                                  'Population Churning',\n",
        "                                  'Community Environment Profile',\n",
        "                                  'Material Deprivation', 'Population Density',\n",
        "                                  'Consumer Opportunity Profile',\n",
        "                                  'Affordability', 'Job Participation',\n",
        "                                  'Segregation', 'Education',\n",
        "                                  'Economic Opportunity Profile', 'Rural', 'Urban']\n",
        "\n",
        "best_lin = gridSearch.best_estimator_\n",
        "print(len(best_lin.coef_))\n",
        "print(len(column_names))\n",
        "\n",
        "for x in range(len(best_lin.coef_)):\n",
        "  print(column_names[x])\n",
        "  print(best_lin.coef_[x])\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWMvwh0vErEr",
        "outputId": "9b42759a-5838-4ab2-d801-d9edee783290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "20\n",
            "Food Accessibility\n",
            "6.608007245004938\n",
            "Health Opportunity Index\n",
            "-0.8326660634481756\n",
            "Walkability\n",
            "-5.019198522003579\n",
            "Air Quality\n",
            "5.397637955155033\n",
            "Access to Care\n",
            "-4.679634473470238\n",
            "Wellness Disparity Profile\n",
            "6.6533562317308315\n",
            "Income Inequality\n",
            "5.497058921663974\n",
            "Employment Accessibility\n",
            "-1.139382682024937\n",
            "Population Churning\n",
            "3.21224003434055\n",
            "Community Environment Profile\n",
            "12.15779820684674\n",
            "Material Deprivation\n",
            "1.6160821167662065\n",
            "Population Density\n",
            "-1.0688242976560947\n",
            "Consumer Opportunity Profile\n",
            "-1.6944769578222074\n",
            "Affordability\n",
            "2.8619760000119374\n",
            "Job Participation\n",
            "2.6034595469643147\n",
            "Segregation\n",
            "4.246222364193954\n",
            "Education\n",
            "17.6990867067704\n",
            "Economic Opportunity Profile\n",
            "1.2139272766531013\n",
            "Rural\n",
            "13.352058018414002\n",
            "Urban\n",
            "13.159298424254256\n"
          ]
        }
      ]
    }
  ]
}